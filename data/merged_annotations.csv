bibkey,inclusion,phenomenon_short,phenomenon_defined,phenomenon_contested,definition_scope,definition_integrity,definition_integrity_detail,task_face_validity,task_source,task_ecology,task_train_val,task_dataset_metadata,dataset_sampling_method,response_format,metric_definition,metric_access,metric_face_validity,metric_aggregation,metric_subscores,metric_metascoring,metric_fewshot,result_interpretation,results_comparison,results_comparison_explanation,results_human_baseline,results_author_validity,results_realism,authorship,benchmark_availability
liMultimodalArXivDataset2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",No,Not defined,Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Short free response (e.g. single word or number), Free response (e.g. summary paragarph)","n-gram (BLEU, ROUGE, chrF), LLM post-processing (extracting answers, reformatting for automated scoring)",Outputs alone,,Simple Mean,No,,,Yes,Yes,No,Yes,Yes,The benchmark is itself realistic,Academia,Yes
sadatMSciNLIDiverseBenchmark2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Widely-agreed,Comprehensive,Single cohesive phenomenon,Not applicable,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Modified from another benchmark (e.g. translation into another language)",Representative task (e.g. answering medical licensing exam questions),"Test, Train",Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)",Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,,Yes,Yes,No,Yes,No,Yes,Academia,Yes
kuratovBABILongTestingLimits2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Comprehensive,Single cohesive phenomenon,Not applicable,Yes,"Modified from another benchmark (e.g. translation into another language), Procedurally-generated task examples (e.g. Creating instances from a template)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)",Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,No,,,Yes,Yes,Yes,No,Yes,No,Mix (multiple authors from industry and academia),Yes
anLevalInstitutingStandardized2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,Widely-agreed,Comprehensive,Single cohesive phenomenon,Not applicable,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Modified from another benchmark (e.g. translation into another language), Procedurally-generated task examples (e.g. Creating instances from a template)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Multiple choice, Short free response (e.g. single word or number), Free response (e.g. summary paragarph), Extended interaction (e.g. conversation, calling an API and processing the response)","Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF), Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,Yes,Simple Mean,Yes,,,Yes,No,No comparisons made,No,No,No,Mix (multiple authors from industry and academia),Yes
mahbubUnveilingEssencePoetry2023,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Widely-agreed,Comprehensive,Single cohesive phenomenon,Not applicable,Yes,Real task examples (e.g. GitHub issues),Complete real task (e.g. providing medical advice to real people interactively),"Test, Train, Validation",Yes,Specific criteria (items were taken from a larger set based on specified rules),Free response (e.g. summary paragarph),"Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF)",Outputs alone,Yes,Simple Mean,No,,,Yes,No,No comparisons made,No,No,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Yes
zhaoFinDVerExplainableClaim2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Domain expert annotators",Partial real task (e.g. answering medical questions collected from real people),"Test, Validation",,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically)",Free response (e.g. summary paragarph),"Exact Match (accuracy, F1, precision, recall), LLM post-processing (extracting answers, reformatting for automated scoring)",Outputs alone,Yes,Simple Mean,Yes,,,Yes,Yes,No comparisons made,Yes,Somehwat,Yes,Academia,Yes
jiangXFACTRMultilingualFactual2020,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Comprehensive,Single cohesive phenomenon,Not applicable,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Specific criteria (items were taken from a larger set based on specified rules),Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,,Yes,No,No comparisons made,No,No,The benchmark is itself realistic,Academia,Yes
mitaStrikingGoldAdvertising2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,Real task examples (e.g. GitHub issues),Complete real task (e.g. providing medical advice to real people interactively),"Test, Train, Validation",Yes,"Random sample (creators defined a task space and sampled from it), Convenience sample (creators found a set of tasks that was readily accessible)",Free response (e.g. summary paragarph),"n-gram (BLEU, ROUGE, chrF), Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM post-processing (extracting answers, reformatting for automated scoring), Distribution (perplexity, calibration, correlation)",Outputs alone,Yes,,Yes,,,Yes,No,No,Yes,Yes,The benchmark is itself realistic,Industry,Yes
guptaTempTabQATemporalQuestion2023,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Crowd-sourced task examples (e.g. Prolific-created tasks)",Representative task (e.g. answering medical licensing exam questions),"Test, Train, Validation",Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)",Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF), Meteor",Outputs alone,Yes,Simple Mean,Yes,,,Yes,Yes,Yes,Yes,Yes,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Yes
huangMetaLogicLogicalReasoning2022,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Comprehensive,Composite phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Crowd-sourced task examples (e.g. Prolific-created tasks), Modified from another benchmark (e.g. translation into another language)",Representative task (e.g. answering medical licensing exam questions),"Test, Train, Validation",Yes,"Random sample (creators defined a task space and sampled from it), Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragarph), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), Macro-F1 for the multi-class certainty prediction",Outputs alone,Yes,Simple Mean,Yes,,,Yes,Yes,Yes,No,Yes,No,Mix (multiple authors from industry and academia),Yes
waghjaleECCOCanWe2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,Widely-agreed,Comprehensive,Composite phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Real task examples (e.g. GitHub issues)",Partial real task (e.g. answering medical questions collected from real people),"Test, Train, Validation",,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Structured response (e.g. valid JSON, API call alone)","Code ""Speedup"" and ""Memory Reduction"" versus reference solutions.",Outputs alone,Yes,Simple Mean,Yes,,,Yes,No,No comparisons made,No,Yes,The benchmark is itself realistic,Academia,Yes
zengEvaluatingLargeLanguage2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Subset,Single cohesive phenomenon,Not applicable,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Modified from another benchmark (e.g. translation into another language), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Representative task (e.g. answering medical licensing exam questions),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)",Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,Yes,Yes,No,Academia,Yes
chenAreWeRight2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Comprehensive,Composite phenomenon,Yes,Yes,Modified from another benchmark (e.g. translation into another language),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Specific criteria (items were taken from a larger set based on specified rules),Multiple choice,"Exact Match (accuracy, F1, precision, recall), Custom metrics: multi-modal gain, multi-modal leakage",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,No,Yes,No,Mix (multiple authors from industry and academia),Yes
wangJourneyBenchChallengingOnestop2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,Contested,Comprehensive,Composite phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Expert-crafted task examples (e.g. hand-written examples), Crowd-sourced task examples (e.g. Prolific-created tasks), Modified from another benchmark (e.g. translation into another language), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Multiple choice, Short free response (e.g. single word or number), Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF), LLM post-processing (extracting answers, reformatting for automated scoring)",Outputs alone,Yes,Simple Mean,Yes,recall@k,No,Yes,Yes,Yes,Yes,Yes,No,Academia,Yes
zhangBenchmarkingDataScience2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Comprehensive,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,No,,Yes,,No,Yes,No,No comparisons made,No,Somewhat,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Yes
samdarshiConnectingDotsEvaluating2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Representative task (e.g. answering medical licensing exam questions),Test,Yes,Convenience sample (creators found a set of tasks that was readily accessible),"Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), Distribution (perplexity, calibration, correlation)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,Yes,Yes,Yes,Academia,Yes
jinJailbreakingLargeLanguage2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,Not defined,Subset,Composite phenomenon,Yes,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Multiple choice,"Exact Match (accuracy, F1, precision, recall), A non-defined ""jailbreak success rate"". likely LLM-as-a-Judge but unclear.",Model access required (e.g. logits),Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,No,No,No,Academia,Yes
xieOSWorldBenchmarkingMultimodal2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,Not defined,Subset,Composite phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Expert-crafted task examples (e.g. hand-written examples), Modified from another benchmark (e.g. translation into another language)",Complete real task (e.g. providing medical advice to real people interactively),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Multiple choice, Short free response (e.g. single word or number), Free response (e.g. summary paragraph, executable code), Extended interaction (e.g. conversation, calling an API and processing the response)","Exact Match (accuracy, F1, precision, recall), Execution-based evaluation scripts",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,Yes,,No,Academia,Yes
ushioGenerativeLanguageModels2022,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,Modified from another benchmark (e.g. translation into another language),Representative task (e.g. answering medical licensing exam questions),"Test, Train, Validation",Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragraph, executable code)","n-gram (BLEU, ROUGE, chrF), Human ratings (text quality, preference, NOT manual scoring of other metrics), Correlation (Matthew's correlation, Pearson's r)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,No,Yes,No,Academia,Yes
duEmbSpatialbenchBenchmarkingSpatial2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Subset,Single cohesive phenomenon,Not applicable,Yes,"Procedurally-generated task examples (e.g. Creating instances from a template), LLM-generated task examples (e.g. Filtered from responses to a prompt)","Representative task (e.g. answering medical licensing exam questions), Constructed task (e.g. predicting medical diagnoses from clinicians' notes)",Test,No,Random sample (creators defined a task space and sampled from it),Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Model access required (e.g. logits),Yes,Simple Mean,No,,No,Yes,No,No comparisons made,Yes,No,No,Academia,Yes
royBenchCLAMPBenchmarkEvaluating2023,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Comprehensive,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Modified from another benchmark (e.g. translation into another language)","Partial real task (e.g. answering medical questions collected from real people), Representative task (e.g. answering medical licensing exam questions)","Test, Train",Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragraph, executable code), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,No,No,No,Industry,Yes
mackoMULTITuDELargescaleMultilingual2023,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,"Modified from another benchmark (e.g. translation into another language), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Representative task (e.g. answering medical licensing exam questions),"Test, Train",Yes,Specific criteria (items were taken from a larger set based on specified rules),Multiple choice,"Exact Match (accuracy, F1, precision, recall), Distribution (perplexity, calibration, correlation), Correlation (Matthew's correlation, Pearson's r)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,No,No,No,Academia,Yes
liuMMDUMultiturnMultiimage2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Comprehensive,Single cohesive phenomenon,Not applicable,Yes,LLM-generated task examples (e.g. Filtered from responses to a prompt),Representative task (e.g. answering medical licensing exam questions),Test,No,Targeted items (creators defined a task space and chose tasks within it strategically),"Free response (e.g. summary paragraph, executable code)","LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,Yes,Simple Mean,No,,No,Yes,No,No comparisons made,No,Yes,No,Academia,Yes
wuMedJourneyBenchmarkEvaluation2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Contested,Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Modified from another benchmark (e.g. translation into another language)",Representative task (e.g. answering medical licensing exam questions),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragraph, executable code), Structured response (e.g. valid JSON, API call alone)","Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,Yes,Simple Mean,Yes,consensus@k (plurality vote over k trials),Yes,Yes,No,No comparisons made,No,Yes,Yes,Mix (multiple authors from industry and academia),Yes
liEvaluatingInstructionfollowingRobustness2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,Contested,Comprehensive,Single cohesive phenomenon,Not applicable,"yes, but only a small subset",Modified from another benchmark (e.g. translation into another language),Representative task (e.g. answering medical licensing exam questions),Test,No,"Convenience sample (creators found a set of tasks that was readily accessible), Unknown","Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,Yes,No,No,No comparisons made,No,Yes,No,Industry,Yes
caoSpider2vHowFar2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Expert-crafted task examples (e.g. hand-written examples), Modified from another benchmark (e.g. translation into another language)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragraph, executable code), Extended interaction (e.g. conversation, calling an API and processing the response), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), execution-based verification, file-based comparison, information-based validation",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,No,Yes,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Yes
aggarwalIndicXNLIEvaluatingMultilingual2022,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Comprehensive,Single cohesive phenomenon,Not applicable,Yes,Modified from another benchmark (e.g. translation into another language),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train, Validation",Yes,Unknown,Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,No,,No,Yes,No,No comparisons made,No,No,No,Mix (multiple authors from industry and academia),Yes
guoCanLlmsSolve2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Widely-agreed,Comprehensive,Composite phenomenon,Yes,Yes,Real task examples (e.g. GitHub issues),Partial real task (e.g. answering medical questions collected from real people),Test,Yes,Convenience sample (creators found a set of tasks that was readily accessible),"Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), Many chemistry specific metrics, such as molecule validity, Fingerprint Tanimoto Similarity etc.",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,Yes,No,The benchmark is itself realistic,Academia,Yes
mathaiKGymPlatformDataset2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Widely-agreed,Subset,Single cohesive phenomenon,No,Yes,"Real task examples (e.g. GitHub issues), Procedurally-generated task examples (e.g. Creating instances from a template)",Representative task (e.g. answering medical licensing exam questions),Test,Yes,Specific criteria (items were taken from a larger set based on specified rules),"Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,,No,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Yes
liFRoGEvaluatingFuzzy2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,Contested,Subset,Authors' description is unclear,No,No,Modified from another benchmark (e.g. translation into another language),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)",Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,No,No,No comparisons made,No,No,No,Academia,Yes
maLargeLanguageModels2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Subset,Composite phenomenon,Yes,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Procedurally-generated task examples (e.g. Creating instances from a template)",Representative task (e.g. answering medical licensing exam questions),Test,Yes,Specific criteria (items were taken from a larger set based on specified rules),"Free response (e.g. summary paragraph, executable code), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), Correlation (Matthew's correlation, Pearson's r), Win Rate, Population Block Ratio (PBR), Resource Utilisation Ratio (RUR), Average Population Utilization (APU), Technology Rate (TR)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,Yes,Yes,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Yes
sunHeadtotailHowKnowledgeable2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Subset,Composite phenomenon,Yes,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Procedurally-generated task examples (e.g. Creating instances from a template)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Specific criteria (items were taken from a larger set based on specified rules),Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,Yes,Simple Mean,Yes,,,Yes,No,,No,Yes,No,Industry,Yes
chenExploringPotentialLarge2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Representative task (e.g. answering medical licensing exam questions),Test,No,Random sample (creators defined a task space and sampled from it),"Multiple choice, Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF), Human ratings (text quality, preference, NOT manual scoring of other metrics)",Outputs alone,Yes,Simple Mean,Yes,,,Yes,Yes,Yes,No,Yes,No,Mix (multiple authors from industry and academia),Yes
huangOlympicArenaBenchmarkingMultidiscipline2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Partial real task (e.g. answering medical questions collected from real people),"Test, Validation",Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Multiple choice, Short free response (e.g. single word or number)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,Yes,No,Mix (multiple authors from industry and academia),Yes
friederMathematicalCapabilitiesChatGPT2023,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,Subset,Single cohesive phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Expert-crafted task examples (e.g. hand-written examples), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Free response (e.g. summary paragraph, executable code)","Human ratings (text quality, preference, NOT manual scoring of other metrics)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,Yes,No,Academia,Yes
chevalierLanguageModelsScience2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",No,Contested,Subset,Composite phenomenon,Yes,Yes,Expert-crafted task examples (e.g. hand-written examples),Representative task (e.g. answering medical licensing exam questions),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically)","Free response (e.g. summary paragraph, executable code)","Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,"Maybe - it relies on the GPT-4 evaluator being able to assess the correctness of the answer relative to human key points. If the GPT-4-as-a-judge lacked nuanced scientific understanding, it may fail to evaluate another LLM's response against the key points (e.g., requires capabilities for classic entailment,contradiction task). Howver, they do show high correlation empirically between GPT-4-as-a-judge and human evaluators. ",Simple Mean,Yes,,No,Yes,Yes,No,Yes,Yes,No,Mix (multiple authors from industry and academia),Yes
boginSUPEREvaluatingAgents2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,Contested,Subset,Single cohesive phenomenon,Not applicable,Yes,"Expert-crafted task examples (e.g. hand-written examples), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Partial real task (e.g. answering medical questions collected from real people),Test,,Specific criteria (items were taken from a larger set based on specified rules),"Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,Yes,No,The benchmark is itself realistic,Non-profit,Yes
morabitoSTOPBenchmarkingLarge2024,Include,General form of bias,Yes,Contested,Subset,Composite phenomenon,Yes,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Procedurally-generated task examples (e.g. Creating instances from a template), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,Yes,Yes,No,Academia,Yes
bittonWinoGAViLGamifiedAssociation2022,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Widely-agreed,,Single cohesive phenomenon,,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Free response (e.g. summary paragraph, executable code)",Jaccard Index between model predictions and human-labeled associations,Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,Yes,Yes,No,Academia,Yes
halevyFlexTapeCan`t2024,Include,Specific form of bias,Yes,Widely-agreed,Subset,Composite phenomenon,Yes,Yes,"Modified from another benchmark (e.g. translation into another language), Procedurally-generated task examples (e.g. Creating instances from a template)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Short free response (e.g. single word or number), Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics), Output probability change of attribute",Model access required (e.g. logits),Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,No,No,Academia,Yes
kotturSIMMC20Taskoriented2021,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,Contested,Subset,Composite phenomenon,Yes,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Expert-crafted task examples (e.g. hand-written examples), Crowd-sourced task examples (e.g. Prolific-created tasks), Modified from another benchmark (e.g. translation into another language), Procedurally-generated task examples (e.g. Creating instances from a template), LLM-generated task examples (e.g. Filtered from responses to a prompt)","Partial real task (e.g. answering medical questions collected from real people), Representative task (e.g. answering medical licensing exam questions)","Test, Train, Validation",Yes,"Random sample (creators defined a task space and sampled from it), Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Multiple choice, Free response (e.g. summary paragraph, executable code), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,No,Yes,The benchmark is itself realistic,Industry,Yes
halevyFlexTapeCan`t2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,"Modified from another benchmark (e.g. translation into another language), Procedurally-generated task examples (e.g. Creating instances from a template)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Short free response (e.g. single word or number), Free response (e.g. summary paragraph, executable code)","LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics), Distribution (perplexity, calibration, correlation), Difference in model confidence before and after editing",Model access required (e.g. logits),Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,No,No,Academia,Yes
chenAreWeRight2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,Modified from another benchmark (e.g. translation into another language),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Unknown,Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,No,No,No,Academia,Yes
kuratovBABILongTestingLimits2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Comprehensive,Composite phenomenon,Yes,Yes,Procedurally-generated task examples (e.g. Creating instances from a template),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,No,No,No,Mix (multiple authors from industry and academia),Yes
royBenchCLAMPBenchmarkEvaluating2023,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Composite phenomenon,Yes,Yes,Modified from another benchmark (e.g. translation into another language),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train, Validation",Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), Language-specific parsing metrics, like Lispress Match for Lisp",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,No,No comparisons made,No,No,No,Industry,Yes
zhangBenchmarkingDataScience2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,"Real task examples (e.g. GitHub issues), Procedurally-generated task examples (e.g. Creating instances from a template), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Representative task (e.g. answering medical licensing exam questions),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Extended interaction (e.g. conversation, calling an API and processing the response), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,No,No,Yes,No,Mix (multiple authors from industry and academia),Yes
guoCanLlmsSolve2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Single cohesive phenomenon,No,Yes,Procedurally-generated task examples (e.g. Creating instances from a template),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall), Levenshtein, Validity, MACCS FTS, RDK FTS, Morgan FTS",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,No,The benchmark is itself realistic,Academia,Yes
samdarshiConnectingDotsEvaluating2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,It's based on the New York Times Connections game,Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,,Random sample (creators defined a task space and sampled from it),Clustering multiple words in 4 groups,"Exact Match (accuracy, F1, precision, recall), They introduced two metrics: clustering score and categorical reasoning score",Outputs alone,Yes,Weighted Mean,No,,Yes,Yes,No,No comparisons made,Yes,No,No,Academia,Yes
waghjaleECCOCanWe2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,"Modified from another benchmark (e.g. translation into another language), Adaption of CodeNet into pairs of slow and fast implementations",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train",Yes,Convenience sample (creators found a set of tasks that was readily accessible),"Structured response (e.g. valid JSON, API call alone)",Measurement of code improvement (speed and memory use),Outputs alone,Yes,Simple Mean,Yes,pass@k (any correct answer in k trials),Yes,Yes,No,No comparisons made,No,No,No,Academia,Yes
duEmbSpatialbenchBenchmarkingSpatial2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Comprehensive,Single cohesive phenomenon,Not applicable,Yes,Procedurally-generated task examples (e.g. Creating instances from a template),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,No,,No,Yes,No,No comparisons made,Yes,Yes,No,Academia,Yes
zengEvaluatingLargeLanguage2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Comprehensive,Single cohesive phenomenon,Not applicable,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Modified from another benchmark (e.g. translation into another language), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,No,"Random sample (creators defined a task space and sampled from it), Targeted items (creators defined a task space and chose tasks within it strategically)",Multiple choice,"Exact Match (accuracy, F1, precision, recall), Agreement (consistency over reordered multiple-choice options)",Outputs alone,Yes,Simple Mean,No,,Yes,Yes,No,No comparisons made,Yes,Yes,No,Academia,Yes
liEvaluatingInstructionfollowingRobustness2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,Modified from another benchmark (e.g. translation into another language),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Validation",No,Random sample (creators defined a task space and sampled from it),"Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), Instruction Discrimination Rate (IDR) and Performance Drop Rate (PDR)",Outputs alone,Yes,,No,,Yes,Yes,No,No comparisons made,Yes,No,No,Mix (multiple authors from industry and academia),Yes
chenExploringPotentialLarge2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,"Modified from another benchmark (e.g. translation into another language), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train, Validation",No,Random sample (creators defined a task space and sampled from it),"Multiple choice, Free response (e.g. summary paragraph, executable code)","n-gram (BLEU, ROUGE, chrF)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,No,No comparisons made,Yes,No,No,Mix (multiple authors from industry and academia),Yes
zhaoFinDVerExplainableClaim2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,"Expert-crafted task examples (e.g. hand-written examples), They used experts to craft/annotate some real world documents ",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Validation",No,Random sample (creators defined a task space and sampled from it),"Multiple choice, Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,No,Simple Mean,No,,No,No,No,No comparisons made,Yes,No,No,Academia,Yes
liFRoGEvaluatingFuzzy2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,No,Modified from another benchmark (e.g. translation into another language),Representative task (e.g. answering medical licensing exam questions),Test,Yes,Random sample (creators defined a task space and sampled from it),Multiple choice,"Exact Match (accuracy, F1, precision, recall), Correlation (Matthew's correlation, Pearson's r)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,,No,No,Academia,Yes
ushioGenerativeLanguageModels2022,Exclude,,,,,,,,,,,,,,,,,,,,,,,,,,,,
sunHeadtotailHowKnowledgeable2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Single cohesive phenomenon,Yes,Yes,"Modified from another benchmark (e.g. translation into another language), Procedurally-generated task examples (e.g. Creating instances from a template)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,No,No comparisons made,No,No,No,Industry,Unclear
aggarwalIndicXNLIEvaluatingMultilingual2022,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Comprehensive,Composite phenomenon,Yes,Yes,Modified from another benchmark (e.g. translation into another language),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train, Validation",Yes,Convenience sample (creators found a set of tasks that was readily accessible),Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,No,No,Mix (multiple authors from industry and academia),Yes
jinJailbreakingLargeLanguage2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,"They first train a model using filtered examples, and then generate new prompts using this model.",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,No,Unknown,"Free response (e.g. summary paragraph, executable code)","Jailbreak Success Rate,  Filtered-out Rate, and Perplexity Score ",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,No,No,Academia,Yes
wangJourneyBenchChallengingOnestop2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,"Expert-crafted task examples (e.g. hand-written examples), Crowd-sourced task examples (e.g. Prolific-created tasks), Procedurally-generated task examples (e.g. Creating instances from a template), LLM-generated task examples (e.g. Filtered from responses to a prompt)","Representative task (e.g. answering medical licensing exam questions), Constructed task (e.g. predicting medical diagnoses from clinicians' notes)",Test,Yes,Specific criteria (items were taken from a larger set based on specified rules),"Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF), LLM post-processing (extracting answers, reformatting for automated scoring)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,Yes,Yes,No,Academia,Yes
mathaiKGymPlatformDataset2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,No,Yes,Real task examples (e.g. GitHub issues),Partial real task (e.g. answering medical questions collected from real people),Test,Yes,Specific criteria (items were taken from a larger set based on specified rules),"Free response (e.g. summary paragraph, executable code)",solve rate,Outputs alone,Yes,Simple Mean,Yes,pass@k (any correct answer in k trials),No,Yes,Yes,Yes,No,Yes,No,Mix (multiple authors from industry and academia),Yes
anLevalInstitutingStandardized2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Comprehensive,Composite phenomenon,Yes,Yes,Modified from another benchmark (e.g. translation into another language),"Complete real task (e.g. providing medical advice to real people interactively), Partial real task (e.g. answering medical questions collected from real people), Representative task (e.g. answering medical licensing exam questions), Constructed task (e.g. predicting medical diagnoses from clinicians' notes)",Test,No,Convenience sample (creators found a set of tasks that was readily accessible),"Multiple choice, Short free response (e.g. single word or number), Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,Yes,Simple Mean,No,,Yes,Yes,No,No comparisons made,No,No,No,Mix (multiple authors from industry and academia),Yes
chevalierLanguageModelsScience2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Comprehensive,Composite phenomenon,Yes,Yes,Expert-crafted task examples (e.g. hand-written examples),Representative task (e.g. answering medical licensing exam questions),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically)","Free response (e.g. summary paragraph, executable code)","Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM post-processing (extracting answers, reformatting for automated scoring), Correlation (Matthew's correlation, Pearson's r)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,Yes,No,Academia,Yes
maLargeLanguageModels2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Procedurally-generated task examples (e.g. Creating instances from a template)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), Human ratings (text quality, preference, NOT manual scoring of other metrics), Correlation (Matthew's correlation, Pearson's r)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,Yes,Yes,Yes,Academia,Yes
friederMathematicalCapabilitiesChatGPT2023,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Comprehensive,Single cohesive phenomenon,Yes,Yes,Human exam questions (e.g. GRE questions),Representative task (e.g. answering medical licensing exam questions),Test,No,Convenience sample (creators found a set of tasks that was readily accessible),"Free response (e.g. summary paragraph, executable code)","Human ratings (text quality, preference, NOT manual scoring of other metrics)",Outputs alone,No,Simple Mean,No,,No,Yes,Yes,Yes,No,No,No,Mix (multiple authors from industry and academia),Yes
wuMedJourneyBenchmarkEvaluation2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Comprehensive,Composite phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Real task examples (e.g. GitHub issues)",Complete real task (e.g. providing medical advice to real people interactively),"Test, Train",Yes,Convenience sample (creators found a set of tasks that was readily accessible),"Multiple choice, Free response (e.g. summary paragraph, executable code), Extended interaction (e.g. conversation, calling an API and processing the response)","Exact Match (accuracy, F1, precision, recall), Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics), b-4",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,No,No comparisons made,No,No,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Yes
huangMetaLogicLogicalReasoning2022,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,"Human exam questions (e.g. GRE questions), Modified from another benchmark (e.g. translation into another language)",Representative task (e.g. answering medical licensing exam questions),"Test, Train, Validation",Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,Yes,No,No,Mix (multiple authors from industry and academia),Yes
liuMMDUMultiturnMultiimage2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Composite phenomenon,Yes,Yes,LLM-generated task examples (e.g. Filtered from responses to a prompt),Representative task (e.g. answering medical licensing exam questions),"Test, Train",Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Free response (e.g. summary paragraph, executable code)","LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,Yes,No,Mix (multiple authors from industry and academia),Yes
sadatMSciNLIDiverseBenchmark2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train, Validation",Yes,Random sample (creators defined a task space and sampled from it),Multiple choice,"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,No,,Yes,Yes,No,No comparisons made,Yes,No,No,Academia,Yes
liMultimodalArXivDataset2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Representative task (e.g. answering medical licensing exam questions),"Test, Train",Yes,Specific criteria (items were taken from a larger set based on specified rules),"Multiple choice, Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF), Human ratings (text quality, preference, NOT manual scoring of other metrics), LLM-as-a-Judge (text quality, preferences, NOT extracting answers for other metrics)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,Yes,Yes,No,Academia,Yes
mackoMULTITuDELargescaleMultilingual2023,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Composite phenomenon,Yes,Yes,"Modified from another benchmark (e.g. translation into another language), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Partial real task (e.g. answering medical questions collected from real people),"Test, Train",Yes,Specific criteria (items were taken from a larger set based on specified rules),Multiple choice,"Exact Match (accuracy, F1, precision, recall), Distribution (perplexity, calibration, correlation), Correlation (Matthew's correlation, Pearson's r)",Outputs alone,Yes,"Simple Mean, Weighted Mean, Pairwise correlations, ANOVA within each test language",Yes,,No,Yes,No,No comparisons made,No,No,No,Academia,Yes
huangOlympicArenaBenchmarkingMultidiscipline2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,Human exam questions (e.g. GRE questions),"Representative task (e.g. answering medical licensing exam questions), ","Test, Validation",Yes,Random sample (creators defined a task space and sampled from it),"Multiple choice, Short free response (e.g. single word or number), Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), pass@k",Outputs alone,Yes,Simple Mean,Yes,pass@k (any correct answer in k trials),No,Yes,No,No comparisons made,Yes,No,The benchmark is itself realistic,Academia,Yes
xieOSWorldBenchmarkingMultimodal2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Comprehensive,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions)",Complete real task (e.g. providing medical advice to real people interactively),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Extended interaction (e.g. conversation, calling an API and processing the response)",Success rate,Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,Yes,Yes,The benchmark is itself realistic,Mix (multiple authors from industry and academia),Unclear
kotturSIMMC20Taskoriented2021,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,Procedurally-generated task examples (e.g. Creating instances from a template),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train, Validation",Yes,Targeted items (creators defined a task space and chose tasks within it strategically),"Multiple choice, Free response (e.g. summary paragraph, executable code)","Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF)",Outputs alone,Yes,Simple Mean,Yes,recall@k,No,Yes,Yes,Yes,No,No,No,Industry,Yes
caoSpider2vHowFar2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Expert-crafted task examples (e.g. hand-written examples), Modified from another benchmark (e.g. translation into another language)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically)","Free response (e.g. summary paragraph, executable code), Extended interaction (e.g. conversation, calling an API and processing the response), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall), Verification via execution of created files",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,No,No,Academia,Yes
morabitoSTOPBenchmarkingLarge2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,"Author-crafted task examples (e.g. hand-written examples, manual transformation of existing data into questions), Procedurally-generated task examples (e.g. Creating instances from a template), LLM-generated task examples (e.g. Filtered from responses to a prompt)","Representative task (e.g. answering medical licensing exam questions), Constructed task (e.g. predicting medical diagnoses from clinicians' notes)",Test,Yes,"Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)",Multiple choice,"Exact Match (accuracy, F1, precision, recall), Correlation (Matthew's correlation, Pearson's r)",Outputs alone,Yes,"Simple Mean, Weighted Mean",Yes,,No,Yes,Yes,Yes,Yes,Yes,No,Academia,Yes
mitaStrikingGoldAdvertising2024,Include,"Specific Application (A single use case, where the benchmark is likely to be examples of that use case)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,Real task examples (e.g. GitHub issues),Partial real task (e.g. answering medical questions collected from real people),"Test, Train, Validation",Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragraph, executable code)","n-gram (BLEU, ROUGE, chrF), Human ratings (text quality, preference, NOT manual scoring of other metrics)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,Yes,Yes,Yes,Industry,Yes
boginSUPEREvaluatingAgents2024,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Composite phenomenon,Yes,Yes,"Real task examples (e.g. GitHub issues), Expert-crafted task examples (e.g. hand-written examples), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Targeted items (creators defined a task space and chose tasks within it strategically), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragraph, executable code), Extended interaction (e.g. conversation, calling an API and processing the response), Structured response (e.g. valid JSON, API call alone)","Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,Yes,Yes,The benchmark is itself realistic,Academia,Yes
guptaTempTabQATemporalQuestion2023,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Subset,Composite phenomenon,Yes,Yes,Crowd-sourced task examples (e.g. Prolific-created tasks),Representative task (e.g. answering medical licensing exam questions),"Test, Train, Validation",Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall), n-gram (BLEU, ROUGE, chrF)",Outputs alone,Yes,Simple Mean,Yes,,Yes,Yes,Yes,Yes,Yes,Yes,No,Mix (multiple authors from industry and academia),Yes
mahbubUnveilingEssencePoetry2023,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Single cohesive phenomenon,Not applicable,Yes,"Real task examples (e.g. GitHub issues), Expert-crafted task examples (e.g. hand-written examples)",Partial real task (e.g. answering medical questions collected from real people),Test,Yes,"Convenience sample (creators found a set of tasks that was readily accessible), Specific criteria (items were taken from a larger set based on specified rules)","Free response (e.g. summary paragraph, executable code)","n-gram (BLEU, ROUGE, chrF)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,No,No comparisons made,No,No,No,Mix (multiple authors from industry and academia),Yes
bittonWinoGAViLGamifiedAssociation2022,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",Yes,"Widely-agreed (e.g. if I say ""pronoun resolution"" everyone agrees on what I mean)",Subset,Composite phenomenon,Yes,Yes,"Crowd-sourced task examples (e.g. Prolific-created tasks), Modified from another benchmark (e.g. translation into another language), LLM-generated task examples (e.g. Filtered from responses to a prompt)",Constructed task (e.g. predicting medical diagnoses from clinicians' notes),Test,Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Short free response (e.g. single word or number),Jacard,Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,Yes,Yes,No,Academia,Yes
jiangXFACTRMultilingualFactual2020,Include,"General Capability (A broadly useful ability, which could be relevant to multiple applications)",No,"Contested (e.g. if I say ""reasoning"" there is a lot of variation in what I could mean)",Comprehensive,Single cohesive phenomenon,No,Yes,Procedurally-generated task examples (e.g. Creating instances from a template),Constructed task (e.g. predicting medical diagnoses from clinicians' notes),"Test, Train",Yes,Targeted items (creators defined a task space and chose tasks within it strategically),Short free response (e.g. single word or number),"Exact Match (accuracy, F1, precision, recall)",Outputs alone,Yes,Simple Mean,Yes,,No,Yes,Yes,Yes,No,No,No,Mix (multiple authors from industry and academia),Yes

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import feedparser\n",
    "import tiktoken\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_arxiv_url(categories, keywords, start=0, max_results=5):\n",
    "    assert len(categories) > 0\n",
    "    cat = '(cat:' + categories[0]\n",
    "    for c in categories[1:]:\n",
    "        cat += '+OR+cat:' + c\n",
    "    cat += ')'\n",
    "\n",
    "    assert len(keywords) > 0\n",
    "    kws = ''\n",
    "    for i,d in enumerate(keywords):\n",
    "        for k,v in d.items():\n",
    "            kws += '(' + k + ':' + v[0]\n",
    "            for kw in v[1:]:\n",
    "                kws += '+OR+' + k + ':' + kw\n",
    "            kws += ')'\n",
    "        if i < len(keywords) - 1:\n",
    "            kws += '+AND+'\n",
    "            \n",
    "    url = f'http://export.arxiv.org/api/query?search_query={cat}+AND+{kws}&start={start}&max_results={str(max_results)}'\n",
    "    url = url.replace(' ', '+')\n",
    "    return url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.encoding_for_model(\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['cs.CL','cs.AI','cs.LG']\n",
    "keywords = [{'all':['LLM','\"large language model\"']},{'all':['Benchmark']}]\n",
    "max_results = 20\n",
    "\n",
    "url = build_arxiv_url(categories, keywords, max_results=max_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Reponses: 7567\n",
      "\n",
      "TruthX: Alleviating Hallucinations by Editing Large Language Models in\n",
      "  Truthful Space\n",
      "GenRec: Large Language Model for Generative Recommendation\n",
      "Line Goes Up? Inherent Limitations of Benchmarks for Evaluating Large\n",
      "  Language Models\n",
      "LawBench: Benchmarking Legal Knowledge of Large Language Models\n",
      "Exploring and Benchmarking the Planning Capabilities of Large Language\n",
      "  Models\n",
      "Benchmarking Cognitive Biases in Large Language Models as Evaluators\n",
      "Sequential Large Language Model-Based Hyper-parameter Optimization\n",
      "A Fine-tuning Dataset and Benchmark for Large Language Models for\n",
      "  Protein Understanding\n",
      "Evaluating Interventional Reasoning Capabilities of Large Language\n",
      "  Models\n",
      "Benchmarking Benchmark Leakage in Large Language Models\n",
      "Mathador-LM: A Dynamic Benchmark for Mathematical Reasoning on Large\n",
      "  Language Models\n",
      "Large Language Models as Generalizable Policies for Embodied Tasks\n",
      "Instruction-Following Evaluation for Large Language Models\n",
      "ERBench: An Entity-Relationship based Automatically Verifiable\n",
      "  Hallucination Benchmark for Large Language Models\n",
      "On The Truthfulness of 'Surprisingly Likely' Responses of Large Language\n",
      "  Models\n",
      "Empowering Many, Biasing a Few: Generalist Credit Scoring through Large\n",
      "  Language Models\n",
      "From Generalist to Specialist: A Survey of Large Language Models for\n",
      "  Chemistry\n",
      "Transfer Learning of Tabular Data by Finetuning Large Language Models\n",
      "Instruction Mining: Instruction Data Selection for Tuning Large Language\n",
      "  Models\n",
      "tinyBenchmarks: evaluating LLMs with fewer examples\n",
      "\n",
      "--------------\n",
      "Total Tokens: 5193\n",
      "Average Tokens: 259.65\n",
      "Estimated Tokens: 1964771\n",
      "Estimate Cost (GPT 4o Mini): 0.29471565\n"
     ]
    }
   ],
   "source": [
    "data = urllib.request.urlopen(url)\n",
    "response = feedparser.parse(data)\n",
    "\n",
    "entries = response['entries']\n",
    "print(f\"Total Reponses: {response['feed']['opensearch_totalresults']}\\n\")\n",
    "total_tokens = 0\n",
    "for entry in entries:\n",
    "    print(entry['title'])\n",
    "    abstract_tokens = len(encoding.encode(entry['summary']))\n",
    "    total_tokens += abstract_tokens\n",
    "\n",
    "print('\\n--------------')\n",
    "print(f\"Total Tokens: {total_tokens}\")\n",
    "print(f\"Average Tokens: {total_tokens/len(entries)}\")\n",
    "print(f\"Estimated Tokens: {int(total_tokens/len(entries)*int(response['feed']['opensearch_totalresults']))}\")\n",
    "print(f\"Estimate Cost (GPT 4o Mini): {int(total_tokens/len(entries)*int(response['feed']['opensearch_totalresults']))/1000000*0.15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_df = pd.DataFrame(entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>guidislink</th>\n",
       "      <th>link</th>\n",
       "      <th>updated</th>\n",
       "      <th>updated_parsed</th>\n",
       "      <th>published</th>\n",
       "      <th>published_parsed</th>\n",
       "      <th>title</th>\n",
       "      <th>title_detail</th>\n",
       "      <th>summary</th>\n",
       "      <th>summary_detail</th>\n",
       "      <th>authors</th>\n",
       "      <th>author_detail</th>\n",
       "      <th>author</th>\n",
       "      <th>arxiv_comment</th>\n",
       "      <th>links</th>\n",
       "      <th>arxiv_primary_category</th>\n",
       "      <th>tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://arxiv.org/abs/2402.17811v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2402.17811v2</td>\n",
       "      <td>2024-06-05T11:15:04Z</td>\n",
       "      <td>(2024, 6, 5, 11, 15, 4, 2, 157, 0)</td>\n",
       "      <td>2024-02-27T14:45:04Z</td>\n",
       "      <td>(2024, 2, 27, 14, 45, 4, 1, 58, 0)</td>\n",
       "      <td>TruthX: Alleviating Hallucinations by Editing ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Large Language Models (LLMs) sometimes suffer ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Shaolei Zhang'}, {'name': 'Tian Yu'...</td>\n",
       "      <td>{'name': 'Yang Feng'}</td>\n",
       "      <td>Yang Feng</td>\n",
       "      <td>Accepted to ACL 2024 main conference, Project ...</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2402.17811v2',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://arxiv.org/abs/2307.00457v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2307.00457v2</td>\n",
       "      <td>2023-07-04T20:04:58Z</td>\n",
       "      <td>(2023, 7, 4, 20, 4, 58, 1, 185, 0)</td>\n",
       "      <td>2023-07-02T02:37:07Z</td>\n",
       "      <td>(2023, 7, 2, 2, 37, 7, 6, 183, 0)</td>\n",
       "      <td>GenRec: Large Language Model for Generative Re...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>In recent years, large language models (LLM) h...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Jianchao Ji'}, {'name': 'Zelong Li'...</td>\n",
       "      <td>{'name': 'Yongfeng Zhang'}</td>\n",
       "      <td>Yongfeng Zhang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2307.00457v2',...</td>\n",
       "      <td>{'term': 'cs.IR', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.IR', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://arxiv.org/abs/2502.14318v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2502.14318v1</td>\n",
       "      <td>2025-02-20T07:13:29Z</td>\n",
       "      <td>(2025, 2, 20, 7, 13, 29, 3, 51, 0)</td>\n",
       "      <td>2025-02-20T07:13:29Z</td>\n",
       "      <td>(2025, 2, 20, 7, 13, 29, 3, 51, 0)</td>\n",
       "      <td>Line Goes Up? Inherent Limitations of Benchmar...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Large language models (LLMs) regularly demonst...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'James Fodor'}]</td>\n",
       "      <td>{'name': 'James Fodor'}</td>\n",
       "      <td>James Fodor</td>\n",
       "      <td>10 pages</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2502.14318v1',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://arxiv.org/abs/2309.16289v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2309.16289v1</td>\n",
       "      <td>2023-09-28T09:35:59Z</td>\n",
       "      <td>(2023, 9, 28, 9, 35, 59, 3, 271, 0)</td>\n",
       "      <td>2023-09-28T09:35:59Z</td>\n",
       "      <td>(2023, 9, 28, 9, 35, 59, 3, 271, 0)</td>\n",
       "      <td>LawBench: Benchmarking Legal Knowledge of Larg...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Large language models (LLMs) have demonstrated...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Zhiwei Fei'}, {'name': 'Xiaoyu Shen...</td>\n",
       "      <td>{'name': 'Jidong Ge'}</td>\n",
       "      <td>Jidong Ge</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2309.16289v1',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://arxiv.org/abs/2406.13094v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2406.13094v2</td>\n",
       "      <td>2024-11-02T11:49:49Z</td>\n",
       "      <td>(2024, 11, 2, 11, 49, 49, 5, 307, 0)</td>\n",
       "      <td>2024-06-18T22:57:06Z</td>\n",
       "      <td>(2024, 6, 18, 22, 57, 6, 1, 170, 0)</td>\n",
       "      <td>Exploring and Benchmarking the Planning Capabi...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Classical and natural language planning tasks ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Bernd Bohnet'}, {'name': 'Azade Nov...</td>\n",
       "      <td>{'name': 'Hanie Sedghi'}</td>\n",
       "      <td>Hanie Sedghi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2406.13094v2',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://arxiv.org/abs/2309.17012v3</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2309.17012v3</td>\n",
       "      <td>2024-09-25T16:57:20Z</td>\n",
       "      <td>(2024, 9, 25, 16, 57, 20, 2, 269, 0)</td>\n",
       "      <td>2023-09-29T06:53:10Z</td>\n",
       "      <td>(2023, 9, 29, 6, 53, 10, 4, 272, 0)</td>\n",
       "      <td>Benchmarking Cognitive Biases in Large Languag...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Large Language Models are cognitively biased j...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Ryan Koo'}, {'name': 'Minhwa Lee'},...</td>\n",
       "      <td>{'name': 'Dongyeop Kang'}</td>\n",
       "      <td>Dongyeop Kang</td>\n",
       "      <td>Publishsed at ACL 2024. 29 pages, 9 figures, 1...</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2309.17012v3',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://arxiv.org/abs/2410.20302v3</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2410.20302v3</td>\n",
       "      <td>2025-01-02T23:08:47Z</td>\n",
       "      <td>(2025, 1, 2, 23, 8, 47, 3, 2, 0)</td>\n",
       "      <td>2024-10-27T00:50:30Z</td>\n",
       "      <td>(2024, 10, 27, 0, 50, 30, 6, 301, 0)</td>\n",
       "      <td>Sequential Large Language Model-Based Hyper-pa...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>This study introduces SLLMBO, an innovative fr...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Kanan Mahammadli'}, {'name': 'Seyda...</td>\n",
       "      <td>{'name': 'Seyda Ertekin'}</td>\n",
       "      <td>Seyda Ertekin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2410.20302v3',...</td>\n",
       "      <td>{'term': 'cs.LG', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://arxiv.org/abs/2406.05540v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2406.05540v2</td>\n",
       "      <td>2024-07-08T16:39:35Z</td>\n",
       "      <td>(2024, 7, 8, 16, 39, 35, 0, 190, 0)</td>\n",
       "      <td>2024-06-08T18:11:30Z</td>\n",
       "      <td>(2024, 6, 8, 18, 11, 30, 5, 160, 0)</td>\n",
       "      <td>A Fine-tuning Dataset and Benchmark for Large ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>The parallels between protein sequences and na...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Yiqing Shen'}, {'name': 'Zan Chen'}...</td>\n",
       "      <td>{'name': 'Yu Guang Wang'}</td>\n",
       "      <td>Yu Guang Wang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2406.05540v2',...</td>\n",
       "      <td>{'term': 'q-bio.QM', 'scheme': 'http://arxiv.o...</td>\n",
       "      <td>[{'term': 'q-bio.QM', 'scheme': 'http://arxiv....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>http://arxiv.org/abs/2404.05545v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2404.05545v2</td>\n",
       "      <td>2024-12-22T12:22:53Z</td>\n",
       "      <td>(2024, 12, 22, 12, 22, 53, 6, 357, 0)</td>\n",
       "      <td>2024-04-08T14:15:56Z</td>\n",
       "      <td>(2024, 4, 8, 14, 15, 56, 0, 99, 0)</td>\n",
       "      <td>Evaluating Interventional Reasoning Capabiliti...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Numerous decision-making tasks require estimat...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Tejas Kasetty'}, {'name': 'Divyat M...</td>\n",
       "      <td>{'name': 'Dhanya Sridhar'}</td>\n",
       "      <td>Dhanya Sridhar</td>\n",
       "      <td>17 pages</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2404.05545v2',...</td>\n",
       "      <td>{'term': 'cs.LG', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>http://arxiv.org/abs/2404.18824v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2404.18824v1</td>\n",
       "      <td>2024-04-29T16:05:36Z</td>\n",
       "      <td>(2024, 4, 29, 16, 5, 36, 0, 120, 0)</td>\n",
       "      <td>2024-04-29T16:05:36Z</td>\n",
       "      <td>(2024, 4, 29, 16, 5, 36, 0, 120, 0)</td>\n",
       "      <td>Benchmarking Benchmark Leakage in Large Langua...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Amid the expanding use of pre-training data, t...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Ruijie Xu'}, {'name': 'Zengzhi Wang...</td>\n",
       "      <td>{'name': 'Pengfei Liu'}</td>\n",
       "      <td>Pengfei Liu</td>\n",
       "      <td>30 pages; Homepage: https://gair-nlp.github.io...</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2404.18824v1',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>http://arxiv.org/abs/2406.12572v3</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2406.12572v3</td>\n",
       "      <td>2024-10-15T10:35:17Z</td>\n",
       "      <td>(2024, 10, 15, 10, 35, 17, 1, 289, 0)</td>\n",
       "      <td>2024-06-18T13:02:12Z</td>\n",
       "      <td>(2024, 6, 18, 13, 2, 12, 1, 170, 0)</td>\n",
       "      <td>Mathador-LM: A Dynamic Benchmark for Mathemati...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>We introduce Mathador-LM, a new benchmark for ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Eldar Kurtic'}, {'name': 'Amir Moei...</td>\n",
       "      <td>{'name': 'Dan Alistarh'}</td>\n",
       "      <td>Dan Alistarh</td>\n",
       "      <td>EMNLP 2024</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2406.12572v3',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>http://arxiv.org/abs/2310.17722v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2310.17722v2</td>\n",
       "      <td>2024-04-16T17:54:06Z</td>\n",
       "      <td>(2024, 4, 16, 17, 54, 6, 1, 107, 0)</td>\n",
       "      <td>2023-10-26T18:32:05Z</td>\n",
       "      <td>(2023, 10, 26, 18, 32, 5, 3, 299, 0)</td>\n",
       "      <td>Large Language Models as Generalizable Policie...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>We show that large language models (LLMs) can ...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Andrew Szot'}, {'name': 'Max Schwar...</td>\n",
       "      <td>{'name': 'Alexander Toshev'}</td>\n",
       "      <td>Alexander Toshev</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2310.17722v2',...</td>\n",
       "      <td>{'term': 'cs.LG', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>http://arxiv.org/abs/2311.07911v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2311.07911v1</td>\n",
       "      <td>2023-11-14T05:13:55Z</td>\n",
       "      <td>(2023, 11, 14, 5, 13, 55, 1, 318, 0)</td>\n",
       "      <td>2023-11-14T05:13:55Z</td>\n",
       "      <td>(2023, 11, 14, 5, 13, 55, 1, 318, 0)</td>\n",
       "      <td>Instruction-Following Evaluation for Large Lan...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>One core capability of Large Language Models (...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Jeffrey Zhou'}, {'name': 'Tianjian ...</td>\n",
       "      <td>{'name': 'Le Hou'}</td>\n",
       "      <td>Le Hou</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2311.07911v1',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>http://arxiv.org/abs/2403.05266v3</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2403.05266v3</td>\n",
       "      <td>2024-11-03T18:38:50Z</td>\n",
       "      <td>(2024, 11, 3, 18, 38, 50, 6, 308, 0)</td>\n",
       "      <td>2024-03-08T12:42:36Z</td>\n",
       "      <td>(2024, 3, 8, 12, 42, 36, 4, 68, 0)</td>\n",
       "      <td>ERBench: An Entity-Relationship based Automati...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Large language models (LLMs) have achieved unp...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Jio Oh'}, {'name': 'Soyeon Kim'}, {...</td>\n",
       "      <td>{'name': 'Steven Euijong Whang'}</td>\n",
       "      <td>Steven Euijong Whang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2403.05266v3',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>http://arxiv.org/abs/2311.07692v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2311.07692v2</td>\n",
       "      <td>2025-01-25T20:16:16Z</td>\n",
       "      <td>(2025, 1, 25, 20, 16, 16, 5, 25, 0)</td>\n",
       "      <td>2023-11-13T19:21:25Z</td>\n",
       "      <td>(2023, 11, 13, 19, 21, 25, 0, 317, 0)</td>\n",
       "      <td>On The Truthfulness of 'Surprisingly Likely' R...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>The principle of rewarding a crowd for surpris...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Naman Goel'}]</td>\n",
       "      <td>{'name': 'Naman Goel'}</td>\n",
       "      <td>Naman Goel</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2311.07692v2',...</td>\n",
       "      <td>{'term': 'cs.LG', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>http://arxiv.org/abs/2310.00566v3</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2310.00566v3</td>\n",
       "      <td>2024-02-18T01:24:17Z</td>\n",
       "      <td>(2024, 2, 18, 1, 24, 17, 6, 49, 0)</td>\n",
       "      <td>2023-10-01T03:50:34Z</td>\n",
       "      <td>(2023, 10, 1, 3, 50, 34, 6, 274, 0)</td>\n",
       "      <td>Empowering Many, Biasing a Few: Generalist Cre...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>In the financial industry, credit scoring is a...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Duanyu Feng'}, {'name': 'Yongfu Dai...</td>\n",
       "      <td>{'name': 'Hao Wang'}</td>\n",
       "      <td>Hao Wang</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2310.00566v3',...</td>\n",
       "      <td>{'term': 'cs.LG', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>http://arxiv.org/abs/2412.19994v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2412.19994v1</td>\n",
       "      <td>2024-12-28T03:40:25Z</td>\n",
       "      <td>(2024, 12, 28, 3, 40, 25, 5, 363, 0)</td>\n",
       "      <td>2024-12-28T03:40:25Z</td>\n",
       "      <td>(2024, 12, 28, 3, 40, 25, 5, 363, 0)</td>\n",
       "      <td>From Generalist to Specialist: A Survey of Lar...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Large Language Models (LLMs) have significantl...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Yang Han'}, {'name': 'Ziping Wan'},...</td>\n",
       "      <td>{'name': 'Xin Chen'}</td>\n",
       "      <td>Xin Chen</td>\n",
       "      <td>COLING2025,We maintain an up-to-date Github re...</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2412.19994v1',...</td>\n",
       "      <td>{'term': 'physics.chem-ph', 'scheme': 'http://...</td>\n",
       "      <td>[{'term': 'physics.chem-ph', 'scheme': 'http:/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>http://arxiv.org/abs/2501.06863v1</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2501.06863v1</td>\n",
       "      <td>2025-01-12T16:23:18Z</td>\n",
       "      <td>(2025, 1, 12, 16, 23, 18, 6, 12, 0)</td>\n",
       "      <td>2025-01-12T16:23:18Z</td>\n",
       "      <td>(2025, 1, 12, 16, 23, 18, 6, 12, 0)</td>\n",
       "      <td>Transfer Learning of Tabular Data by Finetunin...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Despite the artificial intelligence (AI) revol...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Shourav B. Rabbani'}, {'name': 'Ibn...</td>\n",
       "      <td>{'name': 'Manar D. Samad'}</td>\n",
       "      <td>Manar D. Samad</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2501.06863v1',...</td>\n",
       "      <td>{'term': 'cs.LG', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.LG', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>http://arxiv.org/abs/2307.06290v3</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2307.06290v3</td>\n",
       "      <td>2024-07-26T18:09:11Z</td>\n",
       "      <td>(2024, 7, 26, 18, 9, 11, 4, 208, 0)</td>\n",
       "      <td>2023-07-12T16:37:31Z</td>\n",
       "      <td>(2023, 7, 12, 16, 37, 31, 2, 193, 0)</td>\n",
       "      <td>Instruction Mining: Instruction Data Selection...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>Large language models (LLMs) are initially pre...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Yihan Cao'}, {'name': 'Yanbin Kang'...</td>\n",
       "      <td>{'name': 'Lichao Sun'}</td>\n",
       "      <td>Lichao Sun</td>\n",
       "      <td>24 pages, 7 figures</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2307.06290v3',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>http://arxiv.org/abs/2402.14992v2</td>\n",
       "      <td>True</td>\n",
       "      <td>http://arxiv.org/abs/2402.14992v2</td>\n",
       "      <td>2024-05-26T22:27:23Z</td>\n",
       "      <td>(2024, 5, 26, 22, 27, 23, 6, 147, 0)</td>\n",
       "      <td>2024-02-22T22:05:23Z</td>\n",
       "      <td>(2024, 2, 22, 22, 5, 23, 3, 53, 0)</td>\n",
       "      <td>tinyBenchmarks: evaluating LLMs with fewer exa...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>The versatility of large language models (LLMs...</td>\n",
       "      <td>{'type': 'text/plain', 'language': None, 'base...</td>\n",
       "      <td>[{'name': 'Felipe Maia Polo'}, {'name': 'Lucas...</td>\n",
       "      <td>{'name': 'Mikhail Yurochkin'}</td>\n",
       "      <td>Mikhail Yurochkin</td>\n",
       "      <td>Proceedings of the 41st International Conferen...</td>\n",
       "      <td>[{'href': 'http://arxiv.org/abs/2402.14992v2',...</td>\n",
       "      <td>{'term': 'cs.CL', 'scheme': 'http://arxiv.org/...</td>\n",
       "      <td>[{'term': 'cs.CL', 'scheme': 'http://arxiv.org...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   id  guidislink  \\\n",
       "0   http://arxiv.org/abs/2402.17811v2        True   \n",
       "1   http://arxiv.org/abs/2307.00457v2        True   \n",
       "2   http://arxiv.org/abs/2502.14318v1        True   \n",
       "3   http://arxiv.org/abs/2309.16289v1        True   \n",
       "4   http://arxiv.org/abs/2406.13094v2        True   \n",
       "5   http://arxiv.org/abs/2309.17012v3        True   \n",
       "6   http://arxiv.org/abs/2410.20302v3        True   \n",
       "7   http://arxiv.org/abs/2406.05540v2        True   \n",
       "8   http://arxiv.org/abs/2404.05545v2        True   \n",
       "9   http://arxiv.org/abs/2404.18824v1        True   \n",
       "10  http://arxiv.org/abs/2406.12572v3        True   \n",
       "11  http://arxiv.org/abs/2310.17722v2        True   \n",
       "12  http://arxiv.org/abs/2311.07911v1        True   \n",
       "13  http://arxiv.org/abs/2403.05266v3        True   \n",
       "14  http://arxiv.org/abs/2311.07692v2        True   \n",
       "15  http://arxiv.org/abs/2310.00566v3        True   \n",
       "16  http://arxiv.org/abs/2412.19994v1        True   \n",
       "17  http://arxiv.org/abs/2501.06863v1        True   \n",
       "18  http://arxiv.org/abs/2307.06290v3        True   \n",
       "19  http://arxiv.org/abs/2402.14992v2        True   \n",
       "\n",
       "                                 link               updated  \\\n",
       "0   http://arxiv.org/abs/2402.17811v2  2024-06-05T11:15:04Z   \n",
       "1   http://arxiv.org/abs/2307.00457v2  2023-07-04T20:04:58Z   \n",
       "2   http://arxiv.org/abs/2502.14318v1  2025-02-20T07:13:29Z   \n",
       "3   http://arxiv.org/abs/2309.16289v1  2023-09-28T09:35:59Z   \n",
       "4   http://arxiv.org/abs/2406.13094v2  2024-11-02T11:49:49Z   \n",
       "5   http://arxiv.org/abs/2309.17012v3  2024-09-25T16:57:20Z   \n",
       "6   http://arxiv.org/abs/2410.20302v3  2025-01-02T23:08:47Z   \n",
       "7   http://arxiv.org/abs/2406.05540v2  2024-07-08T16:39:35Z   \n",
       "8   http://arxiv.org/abs/2404.05545v2  2024-12-22T12:22:53Z   \n",
       "9   http://arxiv.org/abs/2404.18824v1  2024-04-29T16:05:36Z   \n",
       "10  http://arxiv.org/abs/2406.12572v3  2024-10-15T10:35:17Z   \n",
       "11  http://arxiv.org/abs/2310.17722v2  2024-04-16T17:54:06Z   \n",
       "12  http://arxiv.org/abs/2311.07911v1  2023-11-14T05:13:55Z   \n",
       "13  http://arxiv.org/abs/2403.05266v3  2024-11-03T18:38:50Z   \n",
       "14  http://arxiv.org/abs/2311.07692v2  2025-01-25T20:16:16Z   \n",
       "15  http://arxiv.org/abs/2310.00566v3  2024-02-18T01:24:17Z   \n",
       "16  http://arxiv.org/abs/2412.19994v1  2024-12-28T03:40:25Z   \n",
       "17  http://arxiv.org/abs/2501.06863v1  2025-01-12T16:23:18Z   \n",
       "18  http://arxiv.org/abs/2307.06290v3  2024-07-26T18:09:11Z   \n",
       "19  http://arxiv.org/abs/2402.14992v2  2024-05-26T22:27:23Z   \n",
       "\n",
       "                           updated_parsed             published  \\\n",
       "0      (2024, 6, 5, 11, 15, 4, 2, 157, 0)  2024-02-27T14:45:04Z   \n",
       "1      (2023, 7, 4, 20, 4, 58, 1, 185, 0)  2023-07-02T02:37:07Z   \n",
       "2      (2025, 2, 20, 7, 13, 29, 3, 51, 0)  2025-02-20T07:13:29Z   \n",
       "3     (2023, 9, 28, 9, 35, 59, 3, 271, 0)  2023-09-28T09:35:59Z   \n",
       "4    (2024, 11, 2, 11, 49, 49, 5, 307, 0)  2024-06-18T22:57:06Z   \n",
       "5    (2024, 9, 25, 16, 57, 20, 2, 269, 0)  2023-09-29T06:53:10Z   \n",
       "6        (2025, 1, 2, 23, 8, 47, 3, 2, 0)  2024-10-27T00:50:30Z   \n",
       "7     (2024, 7, 8, 16, 39, 35, 0, 190, 0)  2024-06-08T18:11:30Z   \n",
       "8   (2024, 12, 22, 12, 22, 53, 6, 357, 0)  2024-04-08T14:15:56Z   \n",
       "9     (2024, 4, 29, 16, 5, 36, 0, 120, 0)  2024-04-29T16:05:36Z   \n",
       "10  (2024, 10, 15, 10, 35, 17, 1, 289, 0)  2024-06-18T13:02:12Z   \n",
       "11    (2024, 4, 16, 17, 54, 6, 1, 107, 0)  2023-10-26T18:32:05Z   \n",
       "12   (2023, 11, 14, 5, 13, 55, 1, 318, 0)  2023-11-14T05:13:55Z   \n",
       "13   (2024, 11, 3, 18, 38, 50, 6, 308, 0)  2024-03-08T12:42:36Z   \n",
       "14    (2025, 1, 25, 20, 16, 16, 5, 25, 0)  2023-11-13T19:21:25Z   \n",
       "15     (2024, 2, 18, 1, 24, 17, 6, 49, 0)  2023-10-01T03:50:34Z   \n",
       "16   (2024, 12, 28, 3, 40, 25, 5, 363, 0)  2024-12-28T03:40:25Z   \n",
       "17    (2025, 1, 12, 16, 23, 18, 6, 12, 0)  2025-01-12T16:23:18Z   \n",
       "18    (2024, 7, 26, 18, 9, 11, 4, 208, 0)  2023-07-12T16:37:31Z   \n",
       "19   (2024, 5, 26, 22, 27, 23, 6, 147, 0)  2024-02-22T22:05:23Z   \n",
       "\n",
       "                         published_parsed  \\\n",
       "0      (2024, 2, 27, 14, 45, 4, 1, 58, 0)   \n",
       "1       (2023, 7, 2, 2, 37, 7, 6, 183, 0)   \n",
       "2      (2025, 2, 20, 7, 13, 29, 3, 51, 0)   \n",
       "3     (2023, 9, 28, 9, 35, 59, 3, 271, 0)   \n",
       "4     (2024, 6, 18, 22, 57, 6, 1, 170, 0)   \n",
       "5     (2023, 9, 29, 6, 53, 10, 4, 272, 0)   \n",
       "6    (2024, 10, 27, 0, 50, 30, 6, 301, 0)   \n",
       "7     (2024, 6, 8, 18, 11, 30, 5, 160, 0)   \n",
       "8      (2024, 4, 8, 14, 15, 56, 0, 99, 0)   \n",
       "9     (2024, 4, 29, 16, 5, 36, 0, 120, 0)   \n",
       "10    (2024, 6, 18, 13, 2, 12, 1, 170, 0)   \n",
       "11   (2023, 10, 26, 18, 32, 5, 3, 299, 0)   \n",
       "12   (2023, 11, 14, 5, 13, 55, 1, 318, 0)   \n",
       "13     (2024, 3, 8, 12, 42, 36, 4, 68, 0)   \n",
       "14  (2023, 11, 13, 19, 21, 25, 0, 317, 0)   \n",
       "15    (2023, 10, 1, 3, 50, 34, 6, 274, 0)   \n",
       "16   (2024, 12, 28, 3, 40, 25, 5, 363, 0)   \n",
       "17    (2025, 1, 12, 16, 23, 18, 6, 12, 0)   \n",
       "18   (2023, 7, 12, 16, 37, 31, 2, 193, 0)   \n",
       "19     (2024, 2, 22, 22, 5, 23, 3, 53, 0)   \n",
       "\n",
       "                                                title  \\\n",
       "0   TruthX: Alleviating Hallucinations by Editing ...   \n",
       "1   GenRec: Large Language Model for Generative Re...   \n",
       "2   Line Goes Up? Inherent Limitations of Benchmar...   \n",
       "3   LawBench: Benchmarking Legal Knowledge of Larg...   \n",
       "4   Exploring and Benchmarking the Planning Capabi...   \n",
       "5   Benchmarking Cognitive Biases in Large Languag...   \n",
       "6   Sequential Large Language Model-Based Hyper-pa...   \n",
       "7   A Fine-tuning Dataset and Benchmark for Large ...   \n",
       "8   Evaluating Interventional Reasoning Capabiliti...   \n",
       "9   Benchmarking Benchmark Leakage in Large Langua...   \n",
       "10  Mathador-LM: A Dynamic Benchmark for Mathemati...   \n",
       "11  Large Language Models as Generalizable Policie...   \n",
       "12  Instruction-Following Evaluation for Large Lan...   \n",
       "13  ERBench: An Entity-Relationship based Automati...   \n",
       "14  On The Truthfulness of 'Surprisingly Likely' R...   \n",
       "15  Empowering Many, Biasing a Few: Generalist Cre...   \n",
       "16  From Generalist to Specialist: A Survey of Lar...   \n",
       "17  Transfer Learning of Tabular Data by Finetunin...   \n",
       "18  Instruction Mining: Instruction Data Selection...   \n",
       "19  tinyBenchmarks: evaluating LLMs with fewer exa...   \n",
       "\n",
       "                                         title_detail  \\\n",
       "0   {'type': 'text/plain', 'language': None, 'base...   \n",
       "1   {'type': 'text/plain', 'language': None, 'base...   \n",
       "2   {'type': 'text/plain', 'language': None, 'base...   \n",
       "3   {'type': 'text/plain', 'language': None, 'base...   \n",
       "4   {'type': 'text/plain', 'language': None, 'base...   \n",
       "5   {'type': 'text/plain', 'language': None, 'base...   \n",
       "6   {'type': 'text/plain', 'language': None, 'base...   \n",
       "7   {'type': 'text/plain', 'language': None, 'base...   \n",
       "8   {'type': 'text/plain', 'language': None, 'base...   \n",
       "9   {'type': 'text/plain', 'language': None, 'base...   \n",
       "10  {'type': 'text/plain', 'language': None, 'base...   \n",
       "11  {'type': 'text/plain', 'language': None, 'base...   \n",
       "12  {'type': 'text/plain', 'language': None, 'base...   \n",
       "13  {'type': 'text/plain', 'language': None, 'base...   \n",
       "14  {'type': 'text/plain', 'language': None, 'base...   \n",
       "15  {'type': 'text/plain', 'language': None, 'base...   \n",
       "16  {'type': 'text/plain', 'language': None, 'base...   \n",
       "17  {'type': 'text/plain', 'language': None, 'base...   \n",
       "18  {'type': 'text/plain', 'language': None, 'base...   \n",
       "19  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                                              summary  \\\n",
       "0   Large Language Models (LLMs) sometimes suffer ...   \n",
       "1   In recent years, large language models (LLM) h...   \n",
       "2   Large language models (LLMs) regularly demonst...   \n",
       "3   Large language models (LLMs) have demonstrated...   \n",
       "4   Classical and natural language planning tasks ...   \n",
       "5   Large Language Models are cognitively biased j...   \n",
       "6   This study introduces SLLMBO, an innovative fr...   \n",
       "7   The parallels between protein sequences and na...   \n",
       "8   Numerous decision-making tasks require estimat...   \n",
       "9   Amid the expanding use of pre-training data, t...   \n",
       "10  We introduce Mathador-LM, a new benchmark for ...   \n",
       "11  We show that large language models (LLMs) can ...   \n",
       "12  One core capability of Large Language Models (...   \n",
       "13  Large language models (LLMs) have achieved unp...   \n",
       "14  The principle of rewarding a crowd for surpris...   \n",
       "15  In the financial industry, credit scoring is a...   \n",
       "16  Large Language Models (LLMs) have significantl...   \n",
       "17  Despite the artificial intelligence (AI) revol...   \n",
       "18  Large language models (LLMs) are initially pre...   \n",
       "19  The versatility of large language models (LLMs...   \n",
       "\n",
       "                                       summary_detail  \\\n",
       "0   {'type': 'text/plain', 'language': None, 'base...   \n",
       "1   {'type': 'text/plain', 'language': None, 'base...   \n",
       "2   {'type': 'text/plain', 'language': None, 'base...   \n",
       "3   {'type': 'text/plain', 'language': None, 'base...   \n",
       "4   {'type': 'text/plain', 'language': None, 'base...   \n",
       "5   {'type': 'text/plain', 'language': None, 'base...   \n",
       "6   {'type': 'text/plain', 'language': None, 'base...   \n",
       "7   {'type': 'text/plain', 'language': None, 'base...   \n",
       "8   {'type': 'text/plain', 'language': None, 'base...   \n",
       "9   {'type': 'text/plain', 'language': None, 'base...   \n",
       "10  {'type': 'text/plain', 'language': None, 'base...   \n",
       "11  {'type': 'text/plain', 'language': None, 'base...   \n",
       "12  {'type': 'text/plain', 'language': None, 'base...   \n",
       "13  {'type': 'text/plain', 'language': None, 'base...   \n",
       "14  {'type': 'text/plain', 'language': None, 'base...   \n",
       "15  {'type': 'text/plain', 'language': None, 'base...   \n",
       "16  {'type': 'text/plain', 'language': None, 'base...   \n",
       "17  {'type': 'text/plain', 'language': None, 'base...   \n",
       "18  {'type': 'text/plain', 'language': None, 'base...   \n",
       "19  {'type': 'text/plain', 'language': None, 'base...   \n",
       "\n",
       "                                              authors  \\\n",
       "0   [{'name': 'Shaolei Zhang'}, {'name': 'Tian Yu'...   \n",
       "1   [{'name': 'Jianchao Ji'}, {'name': 'Zelong Li'...   \n",
       "2                           [{'name': 'James Fodor'}]   \n",
       "3   [{'name': 'Zhiwei Fei'}, {'name': 'Xiaoyu Shen...   \n",
       "4   [{'name': 'Bernd Bohnet'}, {'name': 'Azade Nov...   \n",
       "5   [{'name': 'Ryan Koo'}, {'name': 'Minhwa Lee'},...   \n",
       "6   [{'name': 'Kanan Mahammadli'}, {'name': 'Seyda...   \n",
       "7   [{'name': 'Yiqing Shen'}, {'name': 'Zan Chen'}...   \n",
       "8   [{'name': 'Tejas Kasetty'}, {'name': 'Divyat M...   \n",
       "9   [{'name': 'Ruijie Xu'}, {'name': 'Zengzhi Wang...   \n",
       "10  [{'name': 'Eldar Kurtic'}, {'name': 'Amir Moei...   \n",
       "11  [{'name': 'Andrew Szot'}, {'name': 'Max Schwar...   \n",
       "12  [{'name': 'Jeffrey Zhou'}, {'name': 'Tianjian ...   \n",
       "13  [{'name': 'Jio Oh'}, {'name': 'Soyeon Kim'}, {...   \n",
       "14                           [{'name': 'Naman Goel'}]   \n",
       "15  [{'name': 'Duanyu Feng'}, {'name': 'Yongfu Dai...   \n",
       "16  [{'name': 'Yang Han'}, {'name': 'Ziping Wan'},...   \n",
       "17  [{'name': 'Shourav B. Rabbani'}, {'name': 'Ibn...   \n",
       "18  [{'name': 'Yihan Cao'}, {'name': 'Yanbin Kang'...   \n",
       "19  [{'name': 'Felipe Maia Polo'}, {'name': 'Lucas...   \n",
       "\n",
       "                       author_detail                author  \\\n",
       "0              {'name': 'Yang Feng'}             Yang Feng   \n",
       "1         {'name': 'Yongfeng Zhang'}        Yongfeng Zhang   \n",
       "2            {'name': 'James Fodor'}           James Fodor   \n",
       "3              {'name': 'Jidong Ge'}             Jidong Ge   \n",
       "4           {'name': 'Hanie Sedghi'}          Hanie Sedghi   \n",
       "5          {'name': 'Dongyeop Kang'}         Dongyeop Kang   \n",
       "6          {'name': 'Seyda Ertekin'}         Seyda Ertekin   \n",
       "7          {'name': 'Yu Guang Wang'}         Yu Guang Wang   \n",
       "8         {'name': 'Dhanya Sridhar'}        Dhanya Sridhar   \n",
       "9            {'name': 'Pengfei Liu'}           Pengfei Liu   \n",
       "10          {'name': 'Dan Alistarh'}          Dan Alistarh   \n",
       "11      {'name': 'Alexander Toshev'}      Alexander Toshev   \n",
       "12                {'name': 'Le Hou'}                Le Hou   \n",
       "13  {'name': 'Steven Euijong Whang'}  Steven Euijong Whang   \n",
       "14            {'name': 'Naman Goel'}            Naman Goel   \n",
       "15              {'name': 'Hao Wang'}              Hao Wang   \n",
       "16              {'name': 'Xin Chen'}              Xin Chen   \n",
       "17        {'name': 'Manar D. Samad'}        Manar D. Samad   \n",
       "18            {'name': 'Lichao Sun'}            Lichao Sun   \n",
       "19     {'name': 'Mikhail Yurochkin'}     Mikhail Yurochkin   \n",
       "\n",
       "                                        arxiv_comment  \\\n",
       "0   Accepted to ACL 2024 main conference, Project ...   \n",
       "1                                                 NaN   \n",
       "2                                            10 pages   \n",
       "3                                                 NaN   \n",
       "4                                                 NaN   \n",
       "5   Publishsed at ACL 2024. 29 pages, 9 figures, 1...   \n",
       "6                                                 NaN   \n",
       "7                                                 NaN   \n",
       "8                                            17 pages   \n",
       "9   30 pages; Homepage: https://gair-nlp.github.io...   \n",
       "10                                         EMNLP 2024   \n",
       "11                                                NaN   \n",
       "12                                                NaN   \n",
       "13                                                NaN   \n",
       "14                                                NaN   \n",
       "15                                                NaN   \n",
       "16  COLING2025,We maintain an up-to-date Github re...   \n",
       "17                                                NaN   \n",
       "18                                24 pages, 7 figures   \n",
       "19  Proceedings of the 41st International Conferen...   \n",
       "\n",
       "                                                links  \\\n",
       "0   [{'href': 'http://arxiv.org/abs/2402.17811v2',...   \n",
       "1   [{'href': 'http://arxiv.org/abs/2307.00457v2',...   \n",
       "2   [{'href': 'http://arxiv.org/abs/2502.14318v1',...   \n",
       "3   [{'href': 'http://arxiv.org/abs/2309.16289v1',...   \n",
       "4   [{'href': 'http://arxiv.org/abs/2406.13094v2',...   \n",
       "5   [{'href': 'http://arxiv.org/abs/2309.17012v3',...   \n",
       "6   [{'href': 'http://arxiv.org/abs/2410.20302v3',...   \n",
       "7   [{'href': 'http://arxiv.org/abs/2406.05540v2',...   \n",
       "8   [{'href': 'http://arxiv.org/abs/2404.05545v2',...   \n",
       "9   [{'href': 'http://arxiv.org/abs/2404.18824v1',...   \n",
       "10  [{'href': 'http://arxiv.org/abs/2406.12572v3',...   \n",
       "11  [{'href': 'http://arxiv.org/abs/2310.17722v2',...   \n",
       "12  [{'href': 'http://arxiv.org/abs/2311.07911v1',...   \n",
       "13  [{'href': 'http://arxiv.org/abs/2403.05266v3',...   \n",
       "14  [{'href': 'http://arxiv.org/abs/2311.07692v2',...   \n",
       "15  [{'href': 'http://arxiv.org/abs/2310.00566v3',...   \n",
       "16  [{'href': 'http://arxiv.org/abs/2412.19994v1',...   \n",
       "17  [{'href': 'http://arxiv.org/abs/2501.06863v1',...   \n",
       "18  [{'href': 'http://arxiv.org/abs/2307.06290v3',...   \n",
       "19  [{'href': 'http://arxiv.org/abs/2402.14992v2',...   \n",
       "\n",
       "                               arxiv_primary_category  \\\n",
       "0   {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "1   {'term': 'cs.IR', 'scheme': 'http://arxiv.org/...   \n",
       "2   {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "3   {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "4   {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "5   {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "6   {'term': 'cs.LG', 'scheme': 'http://arxiv.org/...   \n",
       "7   {'term': 'q-bio.QM', 'scheme': 'http://arxiv.o...   \n",
       "8   {'term': 'cs.LG', 'scheme': 'http://arxiv.org/...   \n",
       "9   {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "10  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "11  {'term': 'cs.LG', 'scheme': 'http://arxiv.org/...   \n",
       "12  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "13  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "14  {'term': 'cs.LG', 'scheme': 'http://arxiv.org/...   \n",
       "15  {'term': 'cs.LG', 'scheme': 'http://arxiv.org/...   \n",
       "16  {'term': 'physics.chem-ph', 'scheme': 'http://...   \n",
       "17  {'term': 'cs.LG', 'scheme': 'http://arxiv.org/...   \n",
       "18  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "19  {'term': 'cs.CL', 'scheme': 'http://arxiv.org/...   \n",
       "\n",
       "                                                 tags  \n",
       "0   [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "1   [{'term': 'cs.IR', 'scheme': 'http://arxiv.org...  \n",
       "2   [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "3   [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "4   [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "5   [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "6   [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...  \n",
       "7   [{'term': 'q-bio.QM', 'scheme': 'http://arxiv....  \n",
       "8   [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...  \n",
       "9   [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "10  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "11  [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...  \n",
       "12  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "13  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "14  [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...  \n",
       "15  [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...  \n",
       "16  [{'term': 'physics.chem-ph', 'scheme': 'http:/...  \n",
       "17  [{'term': 'cs.LG', 'scheme': 'http://arxiv.org...  \n",
       "18  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  \n",
       "19  [{'term': 'cs.CL', 'scheme': 'http://arxiv.org...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arxiv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICML Proceedings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "icml_url_dict = {2024:'https://proceedings.mlr.press/v235/assets/rss/feed.xml',\n",
    "       2023: 'https://proceedings.mlr.press/v202/assets/rss/feed.xml',\n",
    "       2022: 'https://proceedings.mlr.press/v162/assets/rss/feed.xml',\n",
    "       2021: 'https://proceedings.mlr.press/v139/assets/rss/feed.xml',\n",
    "       2020: 'https://proceedings.mlr.press/v119/assets/rss/feed.xml',\n",
    "       2019: 'https://proceedings.mlr.press/v97/assets/rss/feed.xml',\n",
    "       2018: 'https://proceedings.mlr.press/v80/assets/rss/feed.xml',\n",
    "       #2017: 'https://proceedings.mlr.press/v70/assets/rss/feed.xml',\n",
    "       #2016: 'https://proceedings.mlr.press/v48/assets/rss/feed.xml',\n",
    "       }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_icml_papers(year):\n",
    "    url = icml_url_dict[year]\n",
    "    data = urllib.request.urlopen(url)\n",
    "    response = feedparser.parse(data)\n",
    "\n",
    "    icml = pd.DataFrame(response['entries'])[['title','summary','link']]\n",
    "    icml['year'] = year\n",
    "\n",
    "    is_LLM_title = icml['title'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()))\n",
    "    is_LLM_abstract = icml['summary'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()))\n",
    "    is_benchmark_title = icml['title'].apply(lambda x: ('benchmark' in x.lower()))\n",
    "    is_benchmark_abstract = icml['summary'].apply(lambda x: ('benchmark' in x.lower()))\n",
    "\n",
    "    is_LLM = is_LLM_title | is_LLM_abstract\n",
    "    is_benchmark = is_benchmark_title | is_benchmark_abstract\n",
    "\n",
    "    include = is_LLM & is_benchmark\n",
    "    return icml[include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_icml_papers(year):\n",
    "    url = icml_url_dict[year]\n",
    "    data = urllib.request.urlopen(url)\n",
    "    response = feedparser.parse(data)\n",
    "    icml = pd.DataFrame(response['entries'])[['title','summary','link']]\n",
    "    return len(icml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 171 papers out of 9332 ICML papers\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "total = 0 \n",
    "for year in icml_url_dict.keys():\n",
    "    dfs.append(get_icml_papers(year))\n",
    "    total += count_icml_papers(year)\n",
    "\n",
    "\n",
    "icml_df = pd.concat(dfs)\n",
    "icml_df['venue'] = 'ICML'\n",
    "print(f'Selected {len(icml_df)} papers out of {total} ICML papers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title  summary  link  venue\n",
       "year                             \n",
       "2018      1        1     1      1\n",
       "2020      4        4     4      4\n",
       "2021      3        3     3      3\n",
       "2022      7        7     7      7\n",
       "2023     26       26    26     26\n",
       "2024    130      130   130    130"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "icml_df.groupby('year').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ICLR Proceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_iclr_papers(year):\n",
    "    \n",
    "    iclr = pd.read_csv(f'ICLR_{year}.csv')[['name','abstract','virtualsite_url']]\n",
    "    iclr.columns = ['title','summary','link']\n",
    "    iclr['year'] = year\n",
    "    \n",
    "    is_LLM_title = iclr['title'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()))\n",
    "    is_benchmark_title = iclr['title'].apply(lambda x: ('benchmark' in x.lower()))\n",
    "    \n",
    "    is_LLM_abstract = iclr['summary'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()) if isinstance(x,str) else False)\n",
    "    is_benchmark_abstract = iclr['summary'].apply(lambda x: ('benchmark' in x.lower()) if isinstance(x,str) else False)\n",
    "\n",
    "    is_LLM = is_LLM_title | is_LLM_abstract\n",
    "    is_benchmark = is_benchmark_title | is_benchmark_abstract\n",
    "\n",
    "    include = is_LLM & is_benchmark\n",
    "    return iclr[include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_iclr_papers(year):\n",
    "    \n",
    "    iclr = pd.read_csv(f'ICLR_{year}.csv')[['name','abstract','virtualsite_url']]\n",
    "    return len(iclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 263 out of 7359 total papers.\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "total = 0\n",
    "for year in range(2018,2025):\n",
    "    dfs.append(get_iclr_papers(int(year)))\n",
    "    total += count_iclr_papers(int(year))\n",
    "\n",
    "iclr_df = pd.concat(dfs)\n",
    "iclr_df['venue'] = 'ICLR'\n",
    "print(f'Selected {len(iclr_df)} out of {total} total papers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title  summary  link  venue\n",
       "year                             \n",
       "2018      3        3     3      3\n",
       "2019      4        4     4      4\n",
       "2020      6        6     6      6\n",
       "2021     15       15    15     15\n",
       "2022     22       22    22     22\n",
       "2023     49       49    49     49\n",
       "2024    164      164   164    164"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iclr_df.groupby('year').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NeurIPS Proceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neurips_papers(year):\n",
    "    \n",
    "    neurips = pd.read_csv(f'NeurIPS_{year}.csv')[['name','abstract','virtualsite_url']]\n",
    "    neurips.columns = ['title','summary','link']\n",
    "    neurips['year'] = year\n",
    "    \n",
    "    is_LLM_title = neurips['title'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()))\n",
    "    is_benchmark_title = neurips['title'].apply(lambda x: ('benchmark' in x.lower()))\n",
    "\n",
    "    is_LLM_abstract = neurips['summary'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()) if isinstance(x,str) else False)\n",
    "    is_benchmark_abstract = neurips['summary'].apply(lambda x: ('benchmark' in x.lower()) if isinstance(x,str) else False)\n",
    "\n",
    "    is_LLM = is_LLM_title | is_LLM_abstract\n",
    "    is_benchmark = is_benchmark_title | is_benchmark_abstract\n",
    "\n",
    "    include = is_LLM & is_benchmark\n",
    "    return neurips[include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_neurips_papers(year):\n",
    "    \n",
    "    neurips = pd.read_csv(f'NeurIPS_{year}.csv')[['name','abstract','virtualsite_url']]\n",
    "    return len(neurips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 572 out of 17700 total papers.\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "total = 0\n",
    "for year in range(2018,2025):\n",
    "    dfs.append(get_neurips_papers(int(year)))\n",
    "    total += count_neurips_papers(int(year))\n",
    "\n",
    "neurips_df = pd.concat(dfs)\n",
    "neurips_df['venue'] = 'NeurIPS'\n",
    "print(f'Selected {len(neurips_df)} out of {total} total papers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "      <td>392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title  summary  link  venue\n",
       "year                             \n",
       "2018      2        2     2      2\n",
       "2019      4        4     4      4\n",
       "2020      4        4     4      4\n",
       "2021     12       12    12     12\n",
       "2022     36       36    36     36\n",
       "2023    122      122   122    122\n",
       "2024    392      392   392    392"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neurips_df.groupby('year').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACL Proceedings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lxml.etree as etree\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acl_papers(venue,year):\n",
    "    file = f'{year}.{venue}.xml'\n",
    "    if os.path.exists(file): \n",
    "        response = etree.parse(file)\n",
    "    else:\n",
    "        return None\n",
    "    root = response.getroot()\n",
    "    keys = root.findall(\".//paper\")\n",
    "    keys = [key for key in keys if key.find(\".//abstract\") is not None]\n",
    "    keys = [key for key in keys if key.find(\".//doi\") is not None]\n",
    "    papers = [{'title': etree.tostring(key.find(\".//title\"),method='text',encoding='utf-8').decode('utf-8').strip(),\n",
    "               'abstract': etree.tostring(key.find(\".//abstract\"),method='text',encoding='utf-8').decode('utf-8').strip(),\n",
    "               'link': etree.tostring(key.find(\".//doi\"),method='text',encoding='utf-8').decode('utf-8').strip()} for key in keys]\n",
    "    acl = pd.DataFrame(papers)\n",
    "\n",
    "    acl.columns = ['title','summary','link']\n",
    "    acl['year'] = year\n",
    "    \n",
    "    has_title = acl['title'].apply(lambda x: isinstance(x,str))\n",
    "    has_abstract = acl['summary'].apply(lambda x: isinstance(x,str))\n",
    "    #print(f'{file} Removed {sum(~has_title)} papers without title and {sum(has_title & ~has_abstract)} without abstract.')\n",
    "    acl = acl[has_title & has_abstract]\n",
    "\n",
    "    is_LLM_title = acl['title'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()))\n",
    "    is_benchmark_title = acl['title'].apply(lambda x: ('benchmark' in x.lower()))\n",
    "\n",
    "    is_LLM_abstract = acl['summary'].apply(lambda x: ('LLM' in x) or ('language model' in x.lower()) if isinstance(x,str) else False)\n",
    "    is_benchmark_abstract = acl['summary'].apply(lambda x: ('benchmark' in x.lower()) if isinstance(x,str) else False)\n",
    "\n",
    "    is_LLM = is_LLM_title | is_LLM_abstract\n",
    "    is_benchmark = is_benchmark_title | is_benchmark_abstract\n",
    "\n",
    "    include = is_LLM & is_benchmark\n",
    "    return acl[include]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_acl_papers(venue,year):\n",
    "    file = f'{year}.{venue}.xml'\n",
    "    if os.path.exists(file): \n",
    "        response = etree.parse(file)\n",
    "    else:\n",
    "        return 0\n",
    "    root = response.getroot()\n",
    "    keys = root.findall(\".//paper\")\n",
    "    return len(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1182 out of 11723 total papers.\n"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "total = 0\n",
    "for year in range(2020,2025):\n",
    "    for venue in ['acl','emnlp','naacl']:\n",
    "        dfs.append(get_acl_papers(venue, int(year)))\n",
    "        total += count_acl_papers(venue,int(year))\n",
    "\n",
    "acl_df = pd.concat(dfs)\n",
    "acl_df['venue'] = 'ACL'\n",
    "print(f'Selected {len(acl_df)} out of {total} total papers.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_df['venue'] = acl_df['link'].apply(lambda x: x.replace('10.18653/v1/','').split('.')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_excluded_venues = ['emnlp-tutorials','emnlp-demo','emnlp-demos','emnlp-industry','emnlp-srw',\n",
    "                       'naacl-demo','naacl-demos','naacl-industry','naacl-srw'\n",
    "                       'acl-demos ','acl-demos','acl-demo','acl-industry','acl-srw',]\n",
    "acl_df = acl_df[~acl_df['venue'].isin(acl_excluded_venues)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "acl_df['link'] = acl_df['link'].apply(lambda x: x.replace('10.18653/v1/','https://aclanthology.org/'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46114"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total searched:\n",
    "\n",
    "11723+17700+7359+9332"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df = pd.concat([icml_df,iclr_df,neurips_df,acl_df])\n",
    "conferences_df.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2189, 5)"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>link</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021</th>\n",
       "      <td>132</td>\n",
       "      <td>132</td>\n",
       "      <td>30</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022</th>\n",
       "      <td>219</td>\n",
       "      <td>219</td>\n",
       "      <td>65</td>\n",
       "      <td>219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2023</th>\n",
       "      <td>464</td>\n",
       "      <td>464</td>\n",
       "      <td>197</td>\n",
       "      <td>464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>1300</td>\n",
       "      <td>1300</td>\n",
       "      <td>686</td>\n",
       "      <td>1300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      title  summary  link  venue\n",
       "year                             \n",
       "2018      6        6     6      6\n",
       "2019      8        8     8      8\n",
       "2020     60       60    14     60\n",
       "2021    132      132    30    132\n",
       "2022    219      219    65    219\n",
       "2023    464      464   197    464\n",
       "2024   1300     1300   686   1300"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df.groupby('year').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Results: 2189\n",
      "\n",
      "--------------\n",
      "Total Tokens: 519527\n",
      "Average Tokens: 237.33531292827774\n",
      "Estimate Cost (GPT 4o Mini): 0.07792904999999999\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Results: {len(conferences_df)}\")\n",
    "\n",
    "total_tokens = conferences_df.apply(lambda x: len(encoding.encode(x['summary'])), axis=1).sum()\n",
    "\n",
    "print('\\n--------------')\n",
    "print(f\"Total Tokens: {total_tokens}\")\n",
    "print(f\"Average Tokens: {total_tokens/len(conferences_df)}\")\n",
    "print(f\"Estimate Cost (GPT 4o Mini): {int(total_tokens)/1000000*0.15}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM as Inclusion Criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_article(title, abstract, user_prompt):\n",
    "    client = openai.OpenAI()\n",
    "\n",
    "    response = client.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=[\n",
    "            {\n",
    "                'role': \"system\",\n",
    "                'content': \"You are an academic assistant, filtering articles to identify which ones are relevant to a literature review.\",\n",
    "            },\n",
    "            {\n",
    "                'role': \"user\",\n",
    "                'content': f\"\"\"{user_prompt} \n",
    "                \n",
    "                **Title:** {title}\n",
    "\n",
    "                **Abstract:** {abstract}\n",
    "                \"\"\",\n",
    "            },\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=100,\n",
    "        timeout=30,\n",
    "    )\n",
    "\n",
    "    text = response.choices[0].message.content\n",
    "    if '**Answer:**' in text:\n",
    "        answer = text.split('**Answer:**')[1].strip()\n",
    "    else:\n",
    "        answer = 'Not found'\n",
    "\n",
    "    return text, answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Please read the paper title and abstract below, and tell me whether the paper creates and describes a new benchmark for large language models.\n",
    "                  \n",
    "                After reading the title and abstract, please very briefly describe whether the article implements a new benchmark for large language models. Then, on a new line write **Answer:** followed by a single word answer of 'Yes' or 'No' as to whether the article creates and describes a new benchmark.\"\"\"\n",
    "\n",
    "results = conferences_df.apply(lambda x: score_article(x['title'],x['summary'],user_prompt), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df['inclusion'] = results.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclusion\n",
       "No           1197\n",
       "Yes           896\n",
       "Not found       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df['inclusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Please read the paper title and abstract below, and tell me the primary modality of the dataset being used.\n",
    "                  \n",
    "                After reading the title and abstract, please very briefly describe the primary modality of the article. Then, on a new line write **Answer:** followed by a single word answer describing the primary modality considered in the article. Your answer should be either Language, Image, Video, Audio, Multimodal or Other. Use Other only when the primary modality is not one of the previous options.\"\"\"\n",
    "\n",
    "temp = conferences_df[conferences_df['inclusion'] == 'Yes'].apply(lambda x: score_article(x['title'],x['summary'],user_prompt), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df['modality'] = temp.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclusion  modality  \n",
       "Yes        Language      670\n",
       "           Multimodal    135\n",
       "           Image          57\n",
       "           Video          17\n",
       "           Audio          12\n",
       "           Other           5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df[['inclusion','modality']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\"\"Please read the paper title and abstract below, and tell me the primary focus area of the paper.\n",
    "                  \n",
    "                After reading the title and abstract, please very briefly describe the primary focus of the paper. Then, on a new line write **Answer:** followed by a single word answer of 'Benchmark', 'Technical', 'Methodological' or 'Other' to categorize the primary contribution.\"\"\"\n",
    "\n",
    "results = conferences_df[(conferences_df['inclusion'] == 'Yes') & (conferences_df['modality'] == 'Multimodal')].apply(lambda x: score_article(x['title'],x['summary'],user_prompt), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15           Benchmark\n",
       "16           Benchmark\n",
       "25           Benchmark\n",
       "36           Technical\n",
       "101     Methodological\n",
       "             ...      \n",
       "2004    Methodological\n",
       "2007         Benchmark\n",
       "2037    Methodological\n",
       "2077    Methodological\n",
       "2089         Benchmark\n",
       "Length: 135, dtype: object"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df['contribution'] = results.apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclusion  modality    contribution  \n",
       "Yes        Language    Benchmark         430\n",
       "                       Methodological    215\n",
       "           Multimodal  Benchmark          92\n",
       "                       Methodological     37\n",
       "           Language    Technical          25\n",
       "           Multimodal  Technical           5\n",
       "                       Other               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df[['inclusion','modality','contribution']].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2096, 9)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df.drop('new_contribution',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "conferences_df = pd.read_csv('included_papers_r2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df = conferences_df.merge(acl_df,on=['title','summary','year'],how='left',suffixes=('', '_acl'))\n",
    "conferences_df['venue'] = conferences_df.apply(lambda x: x['venue_acl'] if pd.notna(x['venue_acl']) else x['venue'], axis=1)\n",
    "conferences_df = conferences_df[~(conferences_df['venue'] == 'ACL')]\n",
    "conferences_df['link'] = conferences_df.apply(lambda x: x['link_acl'] if pd.notna(x['link_acl']) else x['link'], axis=1)\n",
    "conferences_df = conferences_df[['title','summary','link','year','venue','inclusion','modality','contribution']]\n",
    "conferences_df.to_csv('included_papers_r3.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "venue\n",
       "emnlp-main     187\n",
       "NeurIPS        171\n",
       "acl-long       151\n",
       "ICLR            58\n",
       "ICML            46\n",
       "naacl-long      32\n",
       "acl-short       11\n",
       "naacl-main       9\n",
       "acl-main         3\n",
       "naacl-short      2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df[conferences_df['modality'] == 'Language']['venue'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2147</th>\n",
       "      <td>DialogBench: Evaluating LLMs as Human-like Dia...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2149</th>\n",
       "      <td>CMB: A Comprehensive Medical Benchmark in Chinese</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2154</th>\n",
       "      <td>PlanRAG: A Plan-then-Retrieval Augmented Gener...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2159</th>\n",
       "      <td>MisgenderMender: A Community-Informed Approach...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2160</th>\n",
       "      <td>Deceptive Semantic Shortcuts on Reasoning Chai...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>Leveraging LLMs for Synthesizing Training Data...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>SuperGLEBer: German Language Understanding Eva...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2165</th>\n",
       "      <td>BUST: Benchmark for the evaluation of detector...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2171</th>\n",
       "      <td>IndiBias: A Benchmark Dataset to Measure Socia...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2172</th>\n",
       "      <td>Struc-Bench: Are Large Language Models Good at...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2179</th>\n",
       "      <td>MuLan: A Study of Fact Mutability in Language ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2181</th>\n",
       "      <td>AgentQuest: A Modular Benchmark Framework to M...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>ZhuJiu-Knowledge: A Fairer Platform for Evalua...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2185</th>\n",
       "      <td>Cross-Task Generalization Abilities of Large L...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2188</th>\n",
       "      <td>Less is More for Improving Automatic Evaluatio...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title link\n",
       "2147  DialogBench: Evaluating LLMs as Human-like Dia...  NaN\n",
       "2149  CMB: A Comprehensive Medical Benchmark in Chinese  NaN\n",
       "2154  PlanRAG: A Plan-then-Retrieval Augmented Gener...  NaN\n",
       "2159  MisgenderMender: A Community-Informed Approach...  NaN\n",
       "2160  Deceptive Semantic Shortcuts on Reasoning Chai...  NaN\n",
       "2161  Leveraging LLMs for Synthesizing Training Data...  NaN\n",
       "2163  SuperGLEBer: German Language Understanding Eva...  NaN\n",
       "2165  BUST: Benchmark for the evaluation of detector...  NaN\n",
       "2171  IndiBias: A Benchmark Dataset to Measure Socia...  NaN\n",
       "2172  Struc-Bench: Are Large Language Models Good at...  NaN\n",
       "2179  MuLan: A Study of Fact Mutability in Language ...  NaN\n",
       "2181  AgentQuest: A Modular Benchmark Framework to M...  NaN\n",
       "2182  ZhuJiu-Knowledge: A Fairer Platform for Evalua...  NaN\n",
       "2185  Cross-Task Generalization Abilities of Large L...  NaN\n",
       "2188  Less is More for Improving Automatic Evaluatio...  NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df[conferences_df['modality'] == 'Language'][['title','link']][-15:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "inclusion\n",
       "No           1248\n",
       "Yes           938\n",
       "Not found       2\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/included_papers_embeddings.csv')['inclusion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "modality\n",
       "Language      709\n",
       "Multimodal    137\n",
       "Image          57\n",
       "Video          17\n",
       "Audio          12\n",
       "Other           6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/included_papers_embeddings.csv')['modality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "contribution\n",
       "Benchmark         450\n",
       "Methodological    227\n",
       "Technical          32\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('../data/included_papers_embeddings.csv')['contribution'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Filtering (for validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import random\n",
    "\n",
    "random.seed(0)\n",
    "random_subset = random.choices(list(range(len(conferences_df))),k=50)\n",
    "\n",
    "subset_df = conferences_df.iloc[random_subset][['title','summary']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "def clear_and_print(message):\n",
    "    clear_output(wait=True)\n",
    "    print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2117\n",
      "PatentEval: Understanding Errors in Patent Generation\n",
      "In this work, we introduce a comprehensive error typology specifically designed\n",
      "for evaluating two distinct tasks in machine-generated patent texts: claims-to-\n",
      "abstract generation, and the generation of the next claim given previous ones.\n",
      "We have also developed a benchmark, PatentEval, for systematically assessing\n",
      "language models in this context. Our study includes a comparative analysis,\n",
      "annotated by humans, of various models. These range from those specifically\n",
      "adapted during training for tasks within the patent domain to the latest\n",
      "general-purpose large language models (LLMs). Furthermore, we explored and\n",
      "evaluated some metrics to approximate human judgments in patent text evaluation,\n",
      "analyzing the extent to which these metrics align with expert assessments. These\n",
      "approaches provide valuable insights into the capabilities and limitations of\n",
      "current language models in the specialized field of patent text generation.\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inclusions = []\n",
    "modalities = []\n",
    "contributions = []\n",
    "for i,row in subset_df.iterrows():\n",
    "    clear_output(wait=False)\n",
    "    print(i)\n",
    "    print(row['title'])\n",
    "    print(textwrap.fill(row['summary'],80))\n",
    "    print('\\n')\n",
    "    inclusion = input('Inclusion: Does the paper introduce a benchmark? Yes or No')\n",
    "    if inclusion == 'No':\n",
    "        inclusions.append('No')\n",
    "        modalities.append(pd.NA)\n",
    "        contributions.append(pd.NA)\n",
    "    else:    \n",
    "        modality = input('Modality: Language, Image, Video, Audio, Multimodal or Other')\n",
    "        if modality == 'Language':\n",
    "            contribution = input('Contribution: Benchmark, Technical, Methodological or Other')\n",
    "            inclusions.append('Yes')\n",
    "            modalities.append('Language')\n",
    "            contributions.append(contribution)        \n",
    "        else:\n",
    "            inclusions.append('Yes')\n",
    "            modalities.append(modality)\n",
    "            contributions.append(pd.NA)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df['inclusion'] = inclusions\n",
    "subset_df['modality'] = modalities\n",
    "subset_df['contribution'] = contributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset_df.to_csv('manual_subset.csv',index=True)\n",
    "subset_df = pd.read_csv('../data/manual_subset.csv',index_col=0)\n",
    "conferences_df = pd.read_csv('../data/included_papers_embeddings.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_df = subset_df.merge(conferences_df,left_on=['title','summary'],right_on=['title','summary'],suffixes=('_manual','_auto'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>inclusion_auto</th>\n",
       "      <th>No</th>\n",
       "      <th>Yes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inclusion_manual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>No</th>\n",
       "      <td>22</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Yes</th>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "inclusion_auto    No  Yes\n",
       "inclusion_manual         \n",
       "No                22    9\n",
       "Yes                5   14"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(validation_df['inclusion_manual'],validation_df['inclusion_auto'],dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>inclusion_manual</th>\n",
       "      <th>modality_manual</th>\n",
       "      <th>contribution_manual</th>\n",
       "      <th>link</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>inclusion_auto</th>\n",
       "      <th>modality_auto</th>\n",
       "      <th>contribution_auto</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LLaMA Pro: Progressive LLaMA with Block Expansion</td>\n",
       "      <td>Humans generally acquire new skills without co...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Language</td>\n",
       "      <td>Technical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>ACL</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.009012330323457718, -0.0016180069651454687,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pcc-tuning: Breaking the Contrastive Learning ...</td>\n",
       "      <td>Semantic Textual Similarity (STS) constitutes ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Language</td>\n",
       "      <td>Technical</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>ACL</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.002708073239773512, -0.013634885661303997, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Efficient Benchmarking (of Language Models)</td>\n",
       "      <td>The increasing versatility of language models ...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Language</td>\n",
       "      <td>Methodological</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>ACL</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.01993037760257721, -0.031682100147008896, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Do Text-to-Vis Benchmarks Test Real Use of Vis...</td>\n",
       "      <td>Large language models are able to generate cod...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Multimodal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2024</td>\n",
       "      <td>ACL</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[-0.018991637974977493, -0.0006011492223478854...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Training Socially Aligned Language Models on S...</td>\n",
       "      <td>The goal of social alignment for AI systems is...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://iclr.cc//virtual/2024/poster/18780</td>\n",
       "      <td>2024</td>\n",
       "      <td>ICLR</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[0.015459313057363033, -0.00032864700187928975...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                title  \\\n",
       "13  LLaMA Pro: Progressive LLaMA with Block Expansion   \n",
       "22  Pcc-tuning: Breaking the Contrastive Learning ...   \n",
       "29        Efficient Benchmarking (of Language Models)   \n",
       "42  Do Text-to-Vis Benchmarks Test Real Use of Vis...   \n",
       "46  Training Socially Aligned Language Models on S...   \n",
       "\n",
       "                                              summary inclusion_manual  \\\n",
       "13  Humans generally acquire new skills without co...              Yes   \n",
       "22  Semantic Textual Similarity (STS) constitutes ...              Yes   \n",
       "29  The increasing versatility of language models ...              Yes   \n",
       "42  Large language models are able to generate cod...              Yes   \n",
       "46  The goal of social alignment for AI systems is...              Yes   \n",
       "\n",
       "   modality_manual contribution_manual  \\\n",
       "13        Language           Technical   \n",
       "22        Language           Technical   \n",
       "29        Language      Methodological   \n",
       "42      Multimodal                 NaN   \n",
       "46              No                 NaN   \n",
       "\n",
       "                                          link  year venue inclusion_auto  \\\n",
       "13                                         NaN  2024   ACL             No   \n",
       "22                                         NaN  2024   ACL             No   \n",
       "29                                         NaN  2024   ACL             No   \n",
       "42                                         NaN  2024   ACL             No   \n",
       "46  https://iclr.cc//virtual/2024/poster/18780  2024  ICLR             No   \n",
       "\n",
       "   modality_auto contribution_auto  \\\n",
       "13           NaN               NaN   \n",
       "22           NaN               NaN   \n",
       "29           NaN               NaN   \n",
       "42           NaN               NaN   \n",
       "46           NaN               NaN   \n",
       "\n",
       "                                            embedding  \n",
       "13  [0.009012330323457718, -0.0016180069651454687,...  \n",
       "22  [0.002708073239773512, -0.013634885661303997, ...  \n",
       "29  [0.01993037760257721, -0.031682100147008896, 0...  \n",
       "42  [-0.018991637974977493, -0.0006011492223478854...  \n",
       "46  [0.015459313057363033, -0.00032864700187928975...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df[(validation_df['inclusion_manual'] == 'Yes') & (validation_df['inclusion_auto'] == 'No')] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modality_manual\n",
      "Language      12\n",
      "Multimodal     3\n",
      "Image          2\n",
      "No             1\n",
      "Video          1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "modality_auto\n",
       "Language      17\n",
       "Image          3\n",
       "Multimodal     2\n",
       "Video          1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(validation_df['modality_manual'].value_counts())\n",
    "validation_df['modality_auto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>modality_auto</th>\n",
       "      <th>Image</th>\n",
       "      <th>Language</th>\n",
       "      <th>Multimodal</th>\n",
       "      <th>Video</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>modality_manual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Image</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Language</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Multimodal</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Video</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "modality_auto    Image  Language  Multimodal  Video\n",
       "modality_manual                                    \n",
       "Image                1         0           1      0\n",
       "Language             0         9           0      0\n",
       "Multimodal           1         0           1      0\n",
       "Video                0         0           0      1"
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(validation_df['modality_manual'],validation_df['modality_auto'],dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validation_df['modality_manual'].value_counts())\n",
    "validation_df['modality_auto'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contribution_auto</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Methodological</th>\n",
       "      <th>Technical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contribution_manual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benchmark</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "contribution_auto    Benchmark  Methodological  Technical\n",
       "contribution_manual                                      \n",
       "Benchmark                    8               1          0"
      ]
     },
     "execution_count": 466,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(validation_df['contribution_manual'],validation_df['contribution_auto'],dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>contribution_manual</th>\n",
       "      <th>Benchmark</th>\n",
       "      <th>Methodological</th>\n",
       "      <th>Technical</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contribution_auto</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Benchmark</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Methodological</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "contribution_manual  Benchmark  Methodological  Technical\n",
       "contribution_auto                                        \n",
       "Benchmark                    8               0          0\n",
       "Methodological               1               0          0"
      ]
     },
     "execution_count": 468,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(validation_df['contribution_auto'],validation_df['contribution_manual'],dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>overall_include_auto</th>\n",
       "      <th>False</th>\n",
       "      <th>True</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall_include_manual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <td>39</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "overall_include_auto    False  True \n",
       "overall_include_manual              \n",
       "False                      39      2\n",
       "True                        1      8"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df['overall_include_manual'] = (validation_df['inclusion_manual'] == 'Yes') & (validation_df['modality_manual'] == 'Language') & (validation_df['contribution_manual'] == 'Benchmark')\n",
    "validation_df['overall_include_auto'] = (validation_df['inclusion_auto'] == 'Yes') & (validation_df['modality_auto'] == 'Language') & (validation_df['contribution_auto'] == 'Benchmark')\n",
    "\n",
    "pd.crosstab(validation_df['overall_include_manual'],validation_df['overall_include_auto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>summary</th>\n",
       "      <th>inclusion_manual</th>\n",
       "      <th>modality_manual</th>\n",
       "      <th>contribution_manual</th>\n",
       "      <th>link</th>\n",
       "      <th>year</th>\n",
       "      <th>venue</th>\n",
       "      <th>inclusion_auto</th>\n",
       "      <th>modality_auto</th>\n",
       "      <th>contribution_auto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>OpenAGI: When LLM Meets Domain Experts</td>\n",
       "      <td>Human Intelligence (HI) excels at combining ba...</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Language</td>\n",
       "      <td>Benchmark</td>\n",
       "      <td>https://neurips.cc//virtual/2023/poster/73509</td>\n",
       "      <td>2023</td>\n",
       "      <td>NeurIPS</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Language</td>\n",
       "      <td>Methodological</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     title  \\\n",
       "32  OpenAGI: When LLM Meets Domain Experts   \n",
       "\n",
       "                                              summary inclusion_manual  \\\n",
       "32  Human Intelligence (HI) excels at combining ba...              Yes   \n",
       "\n",
       "   modality_manual contribution_manual  \\\n",
       "32        Language           Benchmark   \n",
       "\n",
       "                                             link  year    venue  \\\n",
       "32  https://neurips.cc//virtual/2023/poster/73509  2023  NeurIPS   \n",
       "\n",
       "   inclusion_auto modality_auto contribution_auto  \n",
       "32            Yes      Language    Methodological  "
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df[(validation_df['contribution_manual'] == 'Benchmark') & (validation_df['contribution_auto'] != 'Benchmark')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embedding(text):\n",
    "\n",
    "    client = openai.OpenAI()\n",
    "    response = client.embeddings.create(\n",
    "        input=text,\n",
    "        model=\"text-embedding-3-small\"\n",
    "    )\n",
    "\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03420991078019142,\n",
       " -0.008750257082283497,\n",
       " 0.010895868763327599,\n",
       " 0.0008428115979768336,\n",
       " 0.002136621158570051,\n",
       " -0.005187224596738815,\n",
       " -0.0036589261144399643,\n",
       " 0.02474045380949974,\n",
       " -0.04586093872785568,\n",
       " 0.04331976920366287,\n",
       " 0.029127569869160652,\n",
       " 0.014240144751966,\n",
       " -0.059214070439338684,\n",
       " 0.012136487290263176,\n",
       " 0.021516043692827225,\n",
       " 0.0157504640519619,\n",
       " 0.03965185210108757,\n",
       " -0.019310500472784042,\n",
       " 0.007443712092936039,\n",
       " 0.005166247952729464,\n",
       " -0.029894715175032616,\n",
       " -0.025891171768307686,\n",
       " 0.01710495539009571,\n",
       " -0.01941837929189205,\n",
       " 0.04379923269152641,\n",
       " -0.023565761744976044,\n",
       " 0.009679223410785198,\n",
       " -0.015199077315628529,\n",
       " 0.03684697300195694,\n",
       " -0.03284343332052231,\n",
       " 0.021420150995254517,\n",
       " -0.022355109453201294,\n",
       " 0.0052741277031600475,\n",
       " -0.040442969650030136,\n",
       " -0.020197512581944466,\n",
       " 0.017488528043031693,\n",
       " 0.003503099549561739,\n",
       " -0.01018865592777729,\n",
       " 0.009541376493871212,\n",
       " 0.022882523015141487,\n",
       " -0.024344895035028458,\n",
       " -0.048929519951343536,\n",
       " -0.013568892143666744,\n",
       " 0.0363675095140934,\n",
       " 0.02826453000307083,\n",
       " 0.057152364403009415,\n",
       " 0.01328121218830347,\n",
       " -0.012717840261757374,\n",
       " -0.041905343532562256,\n",
       " 0.04219302162528038,\n",
       " -0.014216171577572823,\n",
       " 0.039484038949012756,\n",
       " -0.025651440024375916,\n",
       " -0.014084318652749062,\n",
       " 0.018123820424079895,\n",
       " 0.006125180050730705,\n",
       " 0.037518225610256195,\n",
       " 0.009745149873197079,\n",
       " 0.046628084033727646,\n",
       " -0.00987700279802084,\n",
       " 0.018003953620791435,\n",
       " -0.05974148213863373,\n",
       " -0.008576450869441032,\n",
       " 0.0013897026656195521,\n",
       " -0.045765046030282974,\n",
       " 0.006850372534245253,\n",
       " -0.06376899778842926,\n",
       " 0.006724512670189142,\n",
       " 0.0063948798924684525,\n",
       " 0.004920521285384893,\n",
       " -0.029247434809803963,\n",
       " 0.003793776035308838,\n",
       " 0.018615273758769035,\n",
       " 0.05178234353661537,\n",
       " 0.01389253232628107,\n",
       " -0.012382213957607746,\n",
       " -0.043583475053310394,\n",
       " 0.03212423250079155,\n",
       " 0.03526473417878151,\n",
       " -0.01573847606778145,\n",
       " -0.031452979892492294,\n",
       " 0.010416402481496334,\n",
       " -0.004662808496505022,\n",
       " -0.02934332937002182,\n",
       " 0.040922436863183975,\n",
       " 0.019346458837389946,\n",
       " 0.015067224390804768,\n",
       " 0.003823742736130953,\n",
       " -0.060173001140356064,\n",
       " -0.00866635050624609,\n",
       " 0.012160460464656353,\n",
       " -0.039819665253162384,\n",
       " -0.01358087919652462,\n",
       " 0.008942043408751488,\n",
       " 0.03806961327791214,\n",
       " -0.011423281393945217,\n",
       " 0.025195946916937828,\n",
       " -0.007725398521870375,\n",
       " 0.01650562323629856,\n",
       " 0.0033322898671031,\n",
       " -0.008738270960748196,\n",
       " 0.04339168593287468,\n",
       " 0.057296205312013626,\n",
       " -0.06405667960643768,\n",
       " 0.0642005205154419,\n",
       " -0.04550134018063545,\n",
       " 0.0042612552642822266,\n",
       " -0.002702990546822548,\n",
       " -0.016158008947968483,\n",
       " 0.008270790800452232,\n",
       " -0.01624191552400589,\n",
       " 0.02206742949783802,\n",
       " -0.038740865886211395,\n",
       " -0.008306751027703285,\n",
       " -0.004926514811813831,\n",
       " -0.01539086364209652,\n",
       " -0.027593277394771576,\n",
       " 0.03440169617533684,\n",
       " 0.006209086626768112,\n",
       " 0.029990607872605324,\n",
       " 0.002271470846608281,\n",
       " 0.01108765508979559,\n",
       " 0.033155083656311035,\n",
       " -0.005396991036832333,\n",
       " 0.007977117784321308,\n",
       " -0.02766519784927368,\n",
       " 0.023601721972227097,\n",
       " -0.03833331912755966,\n",
       " 0.002759927185252309,\n",
       " 0.011375335045158863,\n",
       " 0.009199757128953934,\n",
       " 0.03337084501981735,\n",
       " 0.039196357131004333,\n",
       " 0.000703092198818922,\n",
       " -0.03310713917016983,\n",
       " -0.015822382643818855,\n",
       " -0.010218622162938118,\n",
       " 0.04665205627679825,\n",
       " -0.037877827882766724,\n",
       " -0.04168958216905594,\n",
       " 0.024177081882953644,\n",
       " -0.005942383781075478,\n",
       " -0.00950541626662016,\n",
       " -0.02886386215686798,\n",
       " -0.023949334397912025,\n",
       " 0.03504897654056549,\n",
       " -0.00560675747692585,\n",
       " -0.003329293103888631,\n",
       " 0.011806854046881199,\n",
       " 0.025171972811222076,\n",
       " -0.0010630664182826877,\n",
       " -0.051590558141469955,\n",
       " -0.02931935526430607,\n",
       " 0.015067224390804768,\n",
       " -0.00848055724054575,\n",
       " -0.029127569869160652,\n",
       " -0.0029292386025190353,\n",
       " 0.014324051328003407,\n",
       " 0.02462058700621128,\n",
       " -0.01103371474891901,\n",
       " 0.030374180525541306,\n",
       " 0.04578901827335358,\n",
       " 0.016685422509908676,\n",
       " 0.02011360600590706,\n",
       " 0.041282035410404205,\n",
       " 0.032411910593509674,\n",
       " -0.07374189794063568,\n",
       " -0.02390138804912567,\n",
       " -0.030014581978321075,\n",
       " -0.018363554030656815,\n",
       " -0.02970292791724205,\n",
       " 0.0007019684417173266,\n",
       " 0.008216851390898228,\n",
       " -0.11718153208494186,\n",
       " -0.012957572937011719,\n",
       " 0.005885446909815073,\n",
       " -0.005852483678609133,\n",
       " -0.07048152387142181,\n",
       " -0.004210312385112047,\n",
       " -0.026993945240974426,\n",
       " -0.015259010717272758,\n",
       " 0.05638521909713745,\n",
       " -0.04255262017250061,\n",
       " 0.015223050490021706,\n",
       " 0.01224436704069376,\n",
       " 0.0012091536773368716,\n",
       " -0.004776681773364544,\n",
       " 0.0291035957634449,\n",
       " 0.01685323566198349,\n",
       " 0.014875437133014202,\n",
       " -0.050248052924871445,\n",
       " 0.06765267252922058,\n",
       " 0.06966643035411835,\n",
       " 0.05638521909713745,\n",
       " 0.060173001140356064,\n",
       " -0.011471227742731571,\n",
       " 0.04339168593287468,\n",
       " 0.017284754663705826,\n",
       " -0.01878308691084385,\n",
       " -0.027113812044262886,\n",
       " 0.008336718194186687,\n",
       " 0.0037398359272629023,\n",
       " 0.02826453000307083,\n",
       " -0.041665609925985336,\n",
       " 0.0006690051523037255,\n",
       " -0.0472513884305954,\n",
       " 0.004426071885973215,\n",
       " 0.012981546111404896,\n",
       " -0.04336771368980408,\n",
       " -0.019082752987742424,\n",
       " -0.0230503361672163,\n",
       " 0.03442566841840744,\n",
       " 0.04343963414430618,\n",
       " -0.028408369049429893,\n",
       " 0.006412860006093979,\n",
       " -0.0040065390057861805,\n",
       " -0.018027927726507187,\n",
       " 0.014144252054393291,\n",
       " -0.017776207998394966,\n",
       " 0.04461432620882988,\n",
       " -0.017296740785241127,\n",
       " 0.0074017588049173355,\n",
       " 0.019370432943105698,\n",
       " 0.033274952322244644,\n",
       " -0.05600164830684662,\n",
       " 0.008954030461609364,\n",
       " 0.008564463816583157,\n",
       " -0.00327235646545887,\n",
       " 0.052933063358068466,\n",
       " -0.03811756148934364,\n",
       " 0.03830934688448906,\n",
       " -0.014863451011478901,\n",
       " -0.00284982705488801,\n",
       " -0.02874399535357952,\n",
       " -0.016026156023144722,\n",
       " 0.012705853208899498,\n",
       " -0.0181837547570467,\n",
       " -0.016541581600904465,\n",
       " -0.035816121846437454,\n",
       " -0.030158421024680138,\n",
       " -0.008690323680639267,\n",
       " -0.00043264328269287944,\n",
       " -0.000933460658416152,\n",
       " -0.056337274610996246,\n",
       " 0.006682559382170439,\n",
       " 0.027257651090621948,\n",
       " -0.03735041245818138,\n",
       " -0.016217943280935287,\n",
       " 0.030733780935406685,\n",
       " -0.02439284138381481,\n",
       " -0.03253177925944328,\n",
       " -0.0351928174495697,\n",
       " -0.042264942079782486,\n",
       " 2.4137187210726552e-05,\n",
       " -0.015223050490021706,\n",
       " -0.016913168132305145,\n",
       " -0.012873666360974312,\n",
       " 0.007845264859497547,\n",
       " -0.03190847113728523,\n",
       " 0.01915467344224453,\n",
       " -0.044422540813684464,\n",
       " -0.04276838153600693,\n",
       " 0.0021800727117806673,\n",
       " -0.012394200079143047,\n",
       " -0.027904929593205452,\n",
       " -0.03725451976060867,\n",
       " -0.0424087829887867,\n",
       " 0.030518021434545517,\n",
       " -0.03914841264486313,\n",
       " -0.026586398482322693,\n",
       " 0.04593285918235779,\n",
       " -0.04435062035918236,\n",
       " -0.018111834302544594,\n",
       " 0.004947491455823183,\n",
       " -0.015294970944523811,\n",
       " -0.026993945240974426,\n",
       " 0.03380236402153969,\n",
       " -0.0069642458111047745,\n",
       " -0.022163324058055878,\n",
       " 0.02656242437660694,\n",
       " -0.009295649826526642,\n",
       " 0.011669008061289787,\n",
       " 0.054850928485393524,\n",
       " 0.018615273758769035,\n",
       " 0.0007135805208235979,\n",
       " -0.06012505665421486,\n",
       " 0.00235088262706995,\n",
       " -0.03811756148934364,\n",
       " -0.016325822100043297,\n",
       " -0.019562220200896263,\n",
       " 0.07868039608001709,\n",
       " 0.008426617830991745,\n",
       " -0.013449025340378284,\n",
       " -0.009295649826526642,\n",
       " -0.0033472732175141573,\n",
       " -0.003967582248151302,\n",
       " -0.021540017798542976,\n",
       " -0.06113193556666374,\n",
       " 0.010584215633571148,\n",
       " 0.016889195889234543,\n",
       " 0.025771306827664375,\n",
       " -0.016553569585084915,\n",
       " -0.010266569443047047,\n",
       " -0.026274746283888817,\n",
       " -0.01868719421327114,\n",
       " 0.025843225419521332,\n",
       " -0.018855007365345955,\n",
       " 0.00403350917622447,\n",
       " -0.024177081882953644,\n",
       " 0.013796638697385788,\n",
       " 0.013604852370917797,\n",
       " 0.010542262345552444,\n",
       " 0.007935164496302605,\n",
       " 0.04303208738565445,\n",
       " -0.04051489010453224,\n",
       " -0.003413199679926038,\n",
       " -0.020041685551404953,\n",
       " -0.011794867925345898,\n",
       " -0.011327387765049934,\n",
       " -0.022103389725089073,\n",
       " -0.023793507367372513,\n",
       " -0.023949334397912025,\n",
       " -0.010925834998488426,\n",
       " -0.031213246285915375,\n",
       " 0.054611194878816605,\n",
       " 0.02293046936392784,\n",
       " -0.033514685928821564,\n",
       " 0.01565456949174404,\n",
       " -0.020293405279517174,\n",
       " -0.04737125709652901,\n",
       " 0.0028063752688467503,\n",
       " 0.03830934688448906,\n",
       " -0.0042912219651043415,\n",
       " -0.017045021057128906,\n",
       " -0.020521150901913643,\n",
       " -0.020221484825015068,\n",
       " -0.05403583496809006,\n",
       " 0.04825826734304428,\n",
       " 0.005235170945525169,\n",
       " 0.0109078548848629,\n",
       " -0.026011038571596146,\n",
       " 0.0021396176889538765,\n",
       " 0.035216789692640305,\n",
       " 0.005163251422345638,\n",
       " 0.030110474675893784,\n",
       " 0.04631642997264862,\n",
       " 0.02800082415342331,\n",
       " 0.05005626752972603,\n",
       " 0.07254323363304138,\n",
       " -0.00627501355484128,\n",
       " -0.032651644200086594,\n",
       " -0.02836042270064354,\n",
       " 0.056049592792987823,\n",
       " -0.02050916478037834,\n",
       " 0.02994266152381897,\n",
       " 0.009972896426916122,\n",
       " 0.02653845213353634,\n",
       " -0.050631627440452576,\n",
       " -0.06194702908396721,\n",
       " 0.012909626588225365,\n",
       " -0.027329571545124054,\n",
       " 0.0020661994349211454,\n",
       " 0.044302672147750854,\n",
       " 0.03078172728419304,\n",
       " -0.002632568823173642,\n",
       " -0.04010734334588051,\n",
       " -0.009481443092226982,\n",
       " -0.029750874266028404,\n",
       " -0.003946605604141951,\n",
       " -0.013257239013910294,\n",
       " -0.014324051328003407,\n",
       " 0.014851463958621025,\n",
       " -0.012957572937011719,\n",
       " 0.007923178374767303,\n",
       " 0.02934332937002182,\n",
       " -0.010398422367870808,\n",
       " 0.019478313624858856,\n",
       " 0.025795279070734978,\n",
       " 0.01878308691084385,\n",
       " 0.0008128449553623796,\n",
       " 0.009703196585178375,\n",
       " 0.056672900915145874,\n",
       " 0.042720433324575424,\n",
       " -0.020832804962992668,\n",
       " -0.02279861643910408,\n",
       " 0.06861160695552826,\n",
       " -0.029175516217947006,\n",
       " -0.016553569585084915,\n",
       " -0.02644255943596363,\n",
       " 0.016685422509908676,\n",
       " 0.01903480663895607,\n",
       " 0.018243687227368355,\n",
       " -0.021504057571291924,\n",
       " 0.023721588775515556,\n",
       " 0.021276310086250305,\n",
       " 0.0028078737668693066,\n",
       " 0.016062116250395775,\n",
       " 0.031692713499069214,\n",
       " 0.018375540152192116,\n",
       " 0.0008068516617640853,\n",
       " -0.01498331781476736,\n",
       " -0.013556906022131443,\n",
       " 0.03907649219036102,\n",
       " 0.003817749209702015,\n",
       " 0.023829467594623566,\n",
       " 0.006736499723047018,\n",
       " 0.05043983832001686,\n",
       " 0.033538658171892166,\n",
       " 0.04471021890640259,\n",
       " 0.006484779994934797,\n",
       " 0.011135601438581944,\n",
       " -0.024884292855858803,\n",
       " 0.02656242437660694,\n",
       " -0.01698508858680725,\n",
       " 0.012334266677498817,\n",
       " -0.038237426429986954,\n",
       " -0.0016766332555562258,\n",
       " 0.015378877520561218,\n",
       " 0.02086876519024372,\n",
       " 0.050487786531448364,\n",
       " 0.011800860986113548,\n",
       " 0.009127836674451828,\n",
       " -0.015966223552823067,\n",
       " -0.02049717865884304,\n",
       " 0.0011394813191145658,\n",
       " -0.028576182201504707,\n",
       " -0.045645177364349365,\n",
       " -0.0351688414812088,\n",
       " -0.004186338745057583,\n",
       " -0.053028956055641174,\n",
       " -0.021671870723366737,\n",
       " -0.02581925317645073,\n",
       " 0.000621433078777045,\n",
       " -0.022510936483740807,\n",
       " -0.005852483678609133,\n",
       " -0.010404415428638458,\n",
       " -0.03782987967133522,\n",
       " 0.031213246285915375,\n",
       " 0.003275353228673339,\n",
       " 0.001405435148626566,\n",
       " -0.02314622886478901,\n",
       " 0.025291839614510536,\n",
       " -0.000703092198818922,\n",
       " -0.009271676652133465,\n",
       " -0.018111834302544594,\n",
       " -0.0010945313842967153,\n",
       " -0.053412530571222305,\n",
       " 0.009139823727309704,\n",
       " 0.027976850047707558,\n",
       " -0.038381267338991165,\n",
       " 0.025651440024375916,\n",
       " -0.01551073044538498,\n",
       " 0.0035210796631872654,\n",
       " 0.03406606987118721,\n",
       " 0.00518422806635499,\n",
       " -0.03030226193368435,\n",
       " 0.11008542776107788,\n",
       " -0.027856983244419098,\n",
       " 0.005082341376692057,\n",
       " -0.027353543788194656,\n",
       " 0.031692713499069214,\n",
       " 0.010817955248057842,\n",
       " 0.0018459446728229523,\n",
       " 0.021408164873719215,\n",
       " -0.01346101239323616,\n",
       " 0.02206742949783802,\n",
       " -0.028024796396493912,\n",
       " 0.01963413879275322,\n",
       " -0.012142480351030827,\n",
       " -0.0004888307303190231,\n",
       " 0.004231289029121399,\n",
       " -0.017991967499256134,\n",
       " 0.047467149794101715,\n",
       " 0.014971330761909485,\n",
       " -0.011243481189012527,\n",
       " -0.004656814970076084,\n",
       " 0.052549492567777634,\n",
       " 0.021995510905981064,\n",
       " -0.003670912701636553,\n",
       " -0.003874685848131776,\n",
       " 0.024284960702061653,\n",
       " 0.0010915346210822463,\n",
       " -0.020545125007629395,\n",
       " -0.0043961051851511,\n",
       " -0.005052374675869942,\n",
       " 0.07685842365026474,\n",
       " 0.039196357131004333,\n",
       " 0.018938913941383362,\n",
       " -0.030494047328829765,\n",
       " 0.036391481757164,\n",
       " -0.04097038507461548,\n",
       " -0.05015216022729874,\n",
       " 0.05259743705391884,\n",
       " -0.01018865592777729,\n",
       " 0.04252864792943001,\n",
       " 0.0046747950837016106,\n",
       " -0.01152516808360815,\n",
       " -0.021384190768003464,\n",
       " 0.029870741069316864,\n",
       " 0.015175104141235352,\n",
       " 0.042384807020425797,\n",
       " -0.031572844833135605,\n",
       " -0.023913374170660973,\n",
       " -0.013413066044449806,\n",
       " 0.012046587653458118,\n",
       " 0.009625283069908619,\n",
       " 0.022846562787890434,\n",
       " 0.029631009325385094,\n",
       " -0.03651134669780731,\n",
       " 0.03989158570766449,\n",
       " 0.035959962755441666,\n",
       " -0.022642789408564568,\n",
       " -0.003856705967336893,\n",
       " 0.013245252892374992,\n",
       " -0.00866035744547844,\n",
       " 0.04938501492142677,\n",
       " 0.03030226193368435,\n",
       " 0.02122836373746395,\n",
       " -0.020317379385232925,\n",
       " 0.01927454024553299,\n",
       " 0.0327235646545887,\n",
       " 0.00044687744230031967,\n",
       " -0.005364027805626392,\n",
       " 0.002004767768085003,\n",
       " 0.019598178565502167,\n",
       " -0.0068024261854588985,\n",
       " -0.011387321166694164,\n",
       " -0.09733162820339203,\n",
       " 0.022942455485463142,\n",
       " -0.03444964438676834,\n",
       " 0.04924117401242256,\n",
       " -0.01830362156033516,\n",
       " 8.390657603740692e-05,\n",
       " -0.012945585884153843,\n",
       " -0.019718045368790627,\n",
       " -0.02314622886478901,\n",
       " -0.024320920929312706,\n",
       " -0.005199211183935404,\n",
       " -0.028312476351857185,\n",
       " 0.008432610891759396,\n",
       " 0.0049654715694487095,\n",
       " 0.010194648988544941,\n",
       " 0.0315249003469944,\n",
       " 0.04753907024860382,\n",
       " -0.02390138804912567,\n",
       " -0.005367024336010218,\n",
       " 0.025867199525237083,\n",
       " -0.016421716660261154,\n",
       " -0.028767969459295273,\n",
       " 0.03821345418691635,\n",
       " 0.016325822100043297,\n",
       " -0.02593911997973919,\n",
       " -0.02447674795985222,\n",
       " -0.04614861682057381,\n",
       " 0.006044270470738411,\n",
       " 0.025435680523514748,\n",
       " 0.032651644200086594,\n",
       " 0.043583475053310394,\n",
       " -0.02412913367152214,\n",
       " 0.016169996932148933,\n",
       " 0.019454339519143105,\n",
       " -0.012969559989869595,\n",
       " 0.008684330619871616,\n",
       " 0.015714503824710846,\n",
       " -0.011669008061289787,\n",
       " -0.0200177114456892,\n",
       " 0.010080776177346706,\n",
       " -0.0460766963660717,\n",
       " 0.013616838492453098,\n",
       " -0.004426071885973215,\n",
       " -0.041162170469760895,\n",
       " 0.0019223596900701523,\n",
       " 0.02692202478647232,\n",
       " -0.020772870630025864,\n",
       " 0.008366684429347515,\n",
       " -0.015594637021422386,\n",
       " 0.05149466544389725,\n",
       " -0.029487168416380882,\n",
       " 0.029391275718808174,\n",
       " 0.01626588962972164,\n",
       " -0.0023029358126223087,\n",
       " -0.00010329124779673293,\n",
       " 0.006478786468505859,\n",
       " -0.034497588872909546,\n",
       " -0.02984676882624626,\n",
       " -0.0009102365584112704,\n",
       " 0.014168225228786469,\n",
       " 0.011866787448525429,\n",
       " -0.024884292855858803,\n",
       " -0.010740041732788086,\n",
       " -0.0013417560840025544,\n",
       " -0.05614548549056053,\n",
       " -0.007144045550376177,\n",
       " 0.0013365119230002165,\n",
       " -0.019789965823292732,\n",
       " 0.005630730651319027,\n",
       " 0.00890608411282301,\n",
       " -0.0037038761656731367,\n",
       " -0.04389512538909912,\n",
       " 0.0057715740986168385,\n",
       " 0.023014375939965248,\n",
       " 0.0019987744744867086,\n",
       " 0.014623717404901981,\n",
       " 0.00039743250817991793,\n",
       " -0.0272816251963377,\n",
       " 0.013628825545310974,\n",
       " -0.005663693882524967,\n",
       " 0.011794867925345898,\n",
       " 0.011531161144375801,\n",
       " -0.02677818574011326,\n",
       " -0.029726902022957802,\n",
       " 0.014024385251104832,\n",
       " 0.010512295179069042,\n",
       " -0.025531573221087456,\n",
       " -0.04655616357922554,\n",
       " -0.007359805516898632,\n",
       " -0.02826453000307083,\n",
       " -0.0424327552318573,\n",
       " 0.05489887669682503,\n",
       " -0.023014375939965248,\n",
       " -0.01223837397992611,\n",
       " -0.032076284289360046,\n",
       " -0.018938913941383362,\n",
       " 0.014779544435441494,\n",
       " 0.0020916711073368788,\n",
       " 0.01962215267121792,\n",
       " -0.0063409400172531605,\n",
       " -0.015115170739591122,\n",
       " -0.00023523808340542018,\n",
       " 0.020653005689382553,\n",
       " -0.032196152955293655,\n",
       " -0.02701791748404503,\n",
       " 0.008114964701235294,\n",
       " 0.019981753081083298,\n",
       " 0.00927767064422369,\n",
       " 0.013449025340378284,\n",
       " -0.00024572640541009605,\n",
       " -0.0010293539380654693,\n",
       " -0.006592659745365381,\n",
       " -0.03166874125599861,\n",
       " 0.009655250236392021,\n",
       " -0.00027850241167470813,\n",
       " 0.0055887773633003235,\n",
       " -0.03130913898348808,\n",
       " -0.00872628390789032,\n",
       " -0.02994266152381897,\n",
       " -0.03711068257689476,\n",
       " -0.0006776205264031887,\n",
       " 0.010686102323234081,\n",
       " 0.0018849013140425086,\n",
       " -0.004051488824188709,\n",
       " -0.00621508015319705,\n",
       " 0.045765046030282974,\n",
       " 0.04962474852800369,\n",
       " 0.0008450591121800244,\n",
       " -0.023541787639260292,\n",
       " -0.027689170092344284,\n",
       " -0.02097664400935173,\n",
       " 0.028456317260861397,\n",
       " -0.020664991810917854,\n",
       " -0.019670099020004272,\n",
       " -0.0006259281071834266,\n",
       " -0.020293405279517174,\n",
       " -0.02689805068075657,\n",
       " 0.007168019190430641,\n",
       " 0.08069415390491486,\n",
       " 0.014156238175928593,\n",
       " 0.0042912219651043415,\n",
       " -0.014659677632153034,\n",
       " 0.001799496472813189,\n",
       " -0.018519381061196327,\n",
       " 0.01868719421327114,\n",
       " 0.025843225419521332,\n",
       " -0.04109025001525879,\n",
       " -0.0005083090509288013,\n",
       " 0.01036845613270998,\n",
       " -0.03190847113728523,\n",
       " -0.007191992364823818,\n",
       " -0.018579313531517982,\n",
       " -0.009421509690582752,\n",
       " -0.03044610098004341,\n",
       " 0.02302636206150055,\n",
       " -0.04667603224515915,\n",
       " -0.061036042869091034,\n",
       " -0.03953198343515396,\n",
       " 0.004923518281430006,\n",
       " -0.005007424857467413,\n",
       " 0.02883988991379738,\n",
       " 0.006448819767683744,\n",
       " -0.038764838129282,\n",
       " 0.013137373141944408,\n",
       " -0.0008525507873855531,\n",
       " -0.022978415712714195,\n",
       " -0.01733270101249218,\n",
       " 0.010260575450956821,\n",
       " -0.026154879480600357,\n",
       " -0.0003245761035941541,\n",
       " 0.04029913246631622,\n",
       " -0.02895975671708584,\n",
       " -0.04653219133615494,\n",
       " -0.00030753258033655584,\n",
       " 0.03718259930610657,\n",
       " -0.05585780739784241,\n",
       " -0.04039502516388893,\n",
       " -0.017428595572710037,\n",
       " -0.024668533354997635,\n",
       " -0.04919322952628136,\n",
       " 0.031596820801496506,\n",
       " 0.03548049554228783,\n",
       " 0.0024272974114865065,\n",
       " 0.010194648988544941,\n",
       " -0.014108291827142239,\n",
       " 0.019310500472784042,\n",
       " -0.007197985891252756,\n",
       " 0.001652659964747727,\n",
       " -0.0016706398455426097,\n",
       " -0.026993945240974426,\n",
       " 0.024428801611065865,\n",
       " 0.011129608377814293,\n",
       " 0.012993533164262772,\n",
       " -0.04336771368980408,\n",
       " 0.006700539495795965,\n",
       " -0.055713966488838196,\n",
       " -0.018831033259630203,\n",
       " 0.024464759975671768,\n",
       " 0.0099968696013093,\n",
       " -0.005807533860206604,\n",
       " 0.017908060923218727,\n",
       " -0.0103145157918334,\n",
       " -0.006514746230095625,\n",
       " -0.005945380311459303,\n",
       " 0.029127569869160652,\n",
       " 0.03962787985801697,\n",
       " -0.02448873408138752,\n",
       " 0.024668533354997635,\n",
       " -0.016026156023144722,\n",
       " -0.012681880034506321,\n",
       " -0.003820745972916484,\n",
       " 0.005528843961656094,\n",
       " -0.02120439149439335,\n",
       " -0.025555545464158058,\n",
       " -0.01006279606372118,\n",
       " -0.009373563341796398,\n",
       " -0.01280174683779478,\n",
       " 0.04252864792943001,\n",
       " 0.03586407005786896,\n",
       " -0.00660464633256197,\n",
       " 0.02545965276658535,\n",
       " 0.031812578439712524,\n",
       " -0.055809859186410904,\n",
       " -0.03689492121338844,\n",
       " 0.008300757966935635,\n",
       " -0.003479126375168562,\n",
       " 0.015954235568642616,\n",
       " 0.028480289503932,\n",
       " 0.003152489895001054,\n",
       " 0.016169996932148933,\n",
       " -0.018387528136372566,\n",
       " -0.014899411238729954,\n",
       " -0.04933706670999527,\n",
       " -0.02596309222280979,\n",
       " 0.03298727050423622,\n",
       " 0.00031708445749245584,\n",
       " 0.037901800125837326,\n",
       " -0.021611936390399933,\n",
       " -0.019298512488603592,\n",
       " -0.009900975972414017,\n",
       " -0.01383259892463684,\n",
       " 0.020521150901913643,\n",
       " -0.02545965276658535,\n",
       " -0.012693866156041622,\n",
       " 0.01926255226135254,\n",
       " 0.029151542112231255,\n",
       " 0.026706265285611153,\n",
       " 0.041282035410404205,\n",
       " -0.028192609548568726,\n",
       " 0.02898372896015644,\n",
       " 0.011171561665832996,\n",
       " -0.03794974833726883,\n",
       " 0.013449025340378284,\n",
       " -0.02462058700621128,\n",
       " -0.023937348276376724,\n",
       " 0.05149466544389725,\n",
       " -0.05307690426707268,\n",
       " 0.005993327125906944,\n",
       " 0.034617457538843155,\n",
       " -0.008983996696770191,\n",
       " 0.010668122209608555,\n",
       " -0.03092556819319725,\n",
       " -0.03313111141324043,\n",
       " -0.019586192443966866,\n",
       " 0.004533952102065086,\n",
       " -0.01853136718273163,\n",
       " -0.004180345684289932,\n",
       " 0.008336718194186687,\n",
       " 0.022510936483740807,\n",
       " 0.020449232310056686,\n",
       " -0.07671458274126053,\n",
       " 0.0032573731150478125,\n",
       " 0.0376141220331192,\n",
       " 0.0035210796631872654,\n",
       " 0.014312065206468105,\n",
       " 0.00029891717713326216,\n",
       " -0.027713144198060036,\n",
       " 0.015834370627999306,\n",
       " -0.004162365570664406,\n",
       " -0.03380236402153969,\n",
       " 0.026466531679034233,\n",
       " -0.039220333099365234,\n",
       " 0.02836042270064354,\n",
       " 0.005070354789495468,\n",
       " -0.009559356607496738,\n",
       " -0.03924430534243584,\n",
       " -0.011201527900993824,\n",
       " 0.005399987567216158,\n",
       " -0.00037626855191774666,\n",
       " -2.224086165369954e-05,\n",
       " 0.0010053806472569704,\n",
       " 0.03406606987118721,\n",
       " -0.00891807023435831,\n",
       " 0.03684697300195694,\n",
       " 0.009193764068186283,\n",
       " 0.06084425747394562,\n",
       " -0.01988585852086544,\n",
       " 0.016277875751256943,\n",
       " -0.007989104837179184,\n",
       " -0.017272768542170525,\n",
       " 0.00038619499537162483,\n",
       " -0.018651233986020088,\n",
       " -0.0014039368834346533,\n",
       " 0.00841463077813387,\n",
       " -0.0068863327614963055,\n",
       " -0.026106933131814003,\n",
       " 0.021995510905981064,\n",
       " -0.007311858702450991,\n",
       " -0.015414836816489697,\n",
       " -0.0007604033453390002,\n",
       " 0.0015807399759069085,\n",
       " -0.023194175213575363,\n",
       " 0.02689805068075657,\n",
       " 0.0022984410170465708,\n",
       " -0.0007195738144218922,\n",
       " -0.0028797935228794813,\n",
       " 0.030374180525541306,\n",
       " 0.00044050952419638634,\n",
       " -0.017608394846320152,\n",
       " -0.04305605962872505,\n",
       " 0.0009342098492197692,\n",
       " 0.011177554726600647,\n",
       " 0.01686522178351879,\n",
       " 0.006490773055702448,\n",
       " 0.02037731185555458,\n",
       " -0.020437244325876236,\n",
       " 0.021552003920078278,\n",
       " -0.022726695984601974,\n",
       " -0.02510005421936512,\n",
       " 0.05274127796292305,\n",
       " -0.040179263800382614,\n",
       " 0.022115375846624374,\n",
       " -0.034257855266332626,\n",
       " -0.015067224390804768,\n",
       " -0.02608295902609825,\n",
       " -0.012562013231217861,\n",
       " 0.023925362154841423,\n",
       " 0.03320303186774254,\n",
       " -0.016949128359556198,\n",
       " -0.04135395586490631,\n",
       " -0.011860794387757778,\n",
       " 0.03298727050423622,\n",
       " -0.0005221685860306025,\n",
       " 0.027689170092344284,\n",
       " 0.012322280555963516,\n",
       " 0.012609959580004215,\n",
       " 0.030709806829690933,\n",
       " 0.018471434712409973,\n",
       " -0.021000618115067482,\n",
       " 0.024908266961574554,\n",
       " 0.030158421024680138,\n",
       " -0.002311925869435072,\n",
       " 0.003101546783000231,\n",
       " -0.005211197771131992,\n",
       " 0.011974667198956013,\n",
       " 0.02471647970378399,\n",
       " 0.03663121536374092,\n",
       " -0.0005738610634580255,\n",
       " -0.0008008583099581301,\n",
       " 0.047946617007255554,\n",
       " -0.0014608734054490924,\n",
       " -0.02170783095061779,\n",
       " -0.02014956623315811,\n",
       " 0.004815638065338135,\n",
       " 0.02850426360964775,\n",
       " -0.023853441700339317,\n",
       " 0.012538040056824684,\n",
       " 0.02218729630112648,\n",
       " -0.016433702781796455,\n",
       " 0.009721176698803902,\n",
       " 0.03989158570766449,\n",
       " 0.02507608011364937,\n",
       " -0.009331610053777695,\n",
       " -0.058015406131744385,\n",
       " 0.012621946632862091,\n",
       " -0.026969971135258675,\n",
       " 0.017979981377720833,\n",
       " -0.014312065206468105,\n",
       " 0.001164203742519021,\n",
       " 0.0018893963424488902,\n",
       " 0.009661243297159672,\n",
       " 0.01952625997364521,\n",
       " -0.0012196419993415475,\n",
       " 0.0582071915268898,\n",
       " 0.009972896426916122,\n",
       " 0.030350208282470703,\n",
       " 0.009379556402564049,\n",
       " 0.027593277394771576,\n",
       " 0.039579931646585464,\n",
       " -0.01441994495689869,\n",
       " -0.019478313624858856,\n",
       " -0.0008742765639908612,\n",
       " -0.015978209674358368,\n",
       " 0.005025404505431652,\n",
       " -0.03313111141324043,\n",
       " -0.01358087919652462,\n",
       " 0.05734415352344513,\n",
       " 0.030038554221391678,\n",
       " -0.03337084501981735,\n",
       " -0.010086769238114357,\n",
       " -0.012789759784936905,\n",
       " 0.05178234353661537,\n",
       " -0.013904518447816372,\n",
       " -0.0024063207674771547,\n",
       " -0.0019388413056731224,\n",
       " 0.010674115270376205,\n",
       " -0.03190847113728523,\n",
       " 0.006281006615608931,\n",
       " -0.023913374170660973,\n",
       " 0.022510936483740807,\n",
       " 0.011105635203421116,\n",
       " 0.02474045380949974,\n",
       " 0.03464142978191376,\n",
       " 0.020437244325876236,\n",
       " -0.003563032951205969,\n",
       " 0.024764427915215492,\n",
       " 0.014839477837085724,\n",
       " -0.03852510452270508,\n",
       " -0.013221279717981815,\n",
       " -0.007108085788786411,\n",
       " 0.009553363546729088,\n",
       " 0.0022220259997993708,\n",
       " 0.015810396522283554,\n",
       " 0.029271408915519714,\n",
       " -0.007395765278488398,\n",
       " -0.010734048672020435,\n",
       " 0.015978209674358368,\n",
       " -0.021156445145606995,\n",
       " 0.0021336243953555822,\n",
       " 0.044806111603975296,\n",
       " 0.004072465468198061,\n",
       " 0.009319623932242393,\n",
       " -0.020760884508490562,\n",
       " 0.00950541626662016,\n",
       " 0.035816121846437454,\n",
       " -0.019238580018281937,\n",
       " -0.01103371474891901,\n",
       " 0.005729620810598135,\n",
       " -0.02656242437660694,\n",
       " 0.06621427834033966,\n",
       " 0.010362462140619755,\n",
       " -0.037542201578617096,\n",
       " 0.04257659614086151,\n",
       " 0.029511142522096634,\n",
       " 0.001809984794817865,\n",
       " 0.00015451546641997993,\n",
       " 0.01892692595720291,\n",
       " 0.011944700963795185,\n",
       " 0.004494995344430208,\n",
       " -0.03245985880494118,\n",
       " 0.014935370534658432,\n",
       " 0.004923518281430006,\n",
       " -0.017488528043031693,\n",
       " 0.010224616155028343,\n",
       " -0.0021426144521683455,\n",
       " 0.052309758961200714,\n",
       " 0.017308728769421577,\n",
       " 0.00374582945369184,\n",
       " 0.03490513563156128,\n",
       " 0.050008319318294525,\n",
       " -0.007132058963179588,\n",
       " 0.05067957192659378,\n",
       " 0.018747126683592796,\n",
       " 0.01043438259512186,\n",
       " 0.04276838153600693,\n",
       " -0.012957572937011719,\n",
       " -0.02035333774983883,\n",
       " 0.01025458239018917,\n",
       " 0.0014219168806448579,\n",
       " -0.021887630224227905,\n",
       " -0.05441940948367119,\n",
       " 0.007503645494580269,\n",
       " 0.0010862904600799084,\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df['embedding'] = conferences_df['summary'].apply(lambda x: get_embedding(x))\n",
    "conferences_df['embedding'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df.to_csv('included_papers_embeddings.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df = pd.read_csv('final_list.csv')\n",
    "embeddings_df = pd.read_csv('included_papers_embeddings.csv')\n",
    "embeddings_df = embeddings_df[['title','summary','embedding']]\n",
    "conferences_df = conferences_df.merge(embeddings_df,on=['title','summary'],how='left',suffixes=('', '_embeddings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df['embedding'] = conferences_df['embedding'].apply(lambda x: eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Andre\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1419: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-3 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-3 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-3 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-3 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-3 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-3 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-3 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-3 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-3 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=25, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>KMeans</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.cluster.KMeans.html\">?<span>Documentation for KMeans</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>KMeans(n_clusters=25, random_state=42)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=25, random_state=42)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "matrix = np.vstack(conferences_df['embedding'].values)\n",
    "n_clusters = 25\n",
    "\n",
    "kmeans = KMeans(n_clusters = n_clusters, init='k-means++', random_state=42)\n",
    "kmeans.fit(matrix)\n",
    "#df['Cluster'] = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "filtered_cluster\n",
       "16    56\n",
       "6     42\n",
       "15    37\n",
       "23    36\n",
       "11    35\n",
       "4     32\n",
       "1     28\n",
       "12    25\n",
       "2     23\n",
       "17    22\n",
       "14    19\n",
       "8     18\n",
       "0     17\n",
       "24    16\n",
       "18    15\n",
       "7     14\n",
       "9     14\n",
       "5     13\n",
       "20    12\n",
       "13    11\n",
       "22    10\n",
       "21     9\n",
       "19     8\n",
       "10     5\n",
       "3      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conferences_df['filtered_cluster'] = kmeans.labels_\n",
    "conferences_df['filtered_cluster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_means = conferences_df.groupby('filtered_cluster')['embedding'].apply(lambda x: np.array([np.array(l) for l in x]).mean(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = {0:'General Reasoning',\n",
    "                  1: 'Factual Knowledge (Updates)',\n",
    "                  2: 'Medicine', \n",
    "                  3: 'Vision',\n",
    "                  4: 'Factual Knowledge (Hallucination)',\n",
    "                  5: 'European Languages',\n",
    "                  6: 'Domain Reasoning',\n",
    "                  7: 'Long-context',\n",
    "                  8: 'Visual Grounding',\n",
    "                  9: 'Assistant Agents',\n",
    "                  10: 'Jailbreaks',\n",
    "                  11: 'Multiliguality', \n",
    "                  12: 'Coding',\n",
    "                  13: 'Summarization',\n",
    "                  14: 'Dialogue Agents',\n",
    "                  15: 'Multimodal Reasoning',\n",
    "                  16: 'Tool Use',\n",
    "                  17: 'Question Answering',\n",
    "                  18: 'General', \n",
    "                  19: 'Language-Specific',\n",
    "                  20: 'Bias',\n",
    "                  21: 'Updates/Editing',\n",
    "                  22: 'Graphs',\n",
    "                  23: 'General',\n",
    "                  24: 'Trust and Safety',\n",
    "                  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df['cluster_label'] = conferences_df['filtered_cluster'].apply(lambda x: cluster_labels[x])\n",
    "conferences_df.sort_values(by='filtered_cluster',inplace=True)\n",
    "conferences_df.drop('embedding',inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df.to_csv('clustered_papers.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      " (0.66) The WMDP Benchmark: Measuring and Reducing Malicious Use with Unlearning https://proceedings.mlr.press/v235/li24bc.html\n",
      " (0.57) Position: TrustLLM: Trustworthiness in Large Language Models https://proceedings.mlr.press/v235/huang24x.html\n",
      " (0.60) Can LLMs Keep a Secret? Testing  Privacy  Implications of Language Models  via Contextual Integrity Theory https://iclr.cc//virtual/2024/poster/18131\n",
      " (0.72) DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models https://neurips.cc//virtual/2023/poster/73486\n",
      " (0.56) MedSafetyBench: Evaluating and Improving the Medical Safety of Large Language Models https://neurips.cc//virtual/2024/poster/97606\n",
      " (0.62) MultiTrust: A Comprehensive Benchmark Towards Trustworthy Multimodal Large Language Models https://neurips.cc//virtual/2024/poster/97845\n",
      " (0.57) SafeWorld: Geo-Diverse Safety Alignment https://neurips.cc//virtual/2024/poster/94887\n",
      " (0.48) SG-Bench: Evaluating LLM Safety Generalization Across Diverse Tasks and Prompt Types https://neurips.cc//virtual/2024/poster/97610\n",
      " (0.77) SafeText: A Benchmark for Exploring Physical Safety in Language Models https://aclanthology.org/2022.emnlp-main.154\n",
      " (0.62) PrivLM-Bench: A Multi-level Privacy Evaluation Benchmark for Language Models https://aclanthology.org/2024.acl-long.4\n",
      " (0.61) NewsBench: A Systematic Evaluation Framework for Assessing Editorial Capabilities of Large Language Models in Chinese Journalism https://aclanthology.org/2024.acl-long.538\n",
      " (0.49) SafetyBench: Evaluating the Safety of Large Language Models https://aclanthology.org/2024.acl-long.830\n",
      " (0.66) RoTBench: A Multi-Level Benchmark for Evaluating the Robustness of Large Language Models in Tool Learning https://aclanthology.org/2024.emnlp-main.19\n",
      " (0.67) GuardBench: A Large-Scale Benchmark for Guardrail Models https://aclanthology.org/2024.emnlp-main.1022\n",
      " (0.73) The Greatest Good Benchmark: Measuring LLMs’ Alignment with Utilitarian Moral Dilemmas https://aclanthology.org/2024.emnlp-main.1224\n",
      " (0.58) Flames: Benchmarking Value Alignment of LLMs in Chinese https://aclanthology.org/2024.naacl-long.256\n"
     ]
    }
   ],
   "source": [
    "cluster_id = 24\n",
    "print(len(conferences_df[conferences_df['filtered_cluster'] == cluster_id]))\n",
    "for i,row in conferences_df[conferences_df['filtered_cluster'] == cluster_id].iterrows():\n",
    "    dist = np.linalg.norm(row['embedding']-cluster_means[cluster_id])\n",
    "    print(f\" ({dist:.2f}) {row['title']} {row['link']}\")\n",
    "    #print(row['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibtex Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get BibTex Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@inproceedings{chen-etal-2024-copybench,\\n    title = \"{C}opy{B}ench: Measuring Literal and Non-Literal Reproduction of Copyright-Protected Text in Language Model Generation\",\\n    author = \"Chen, Tong  and\\n      Asai, Akari  and\\n      Mireshghallah, Niloofar  and\\n      Min, Sewon  and\\n      Grimmelmann, James  and\\n      Choi, Yejin  and\\n      Hajishirzi, Hannaneh  and\\n      Zettlemoyer, Luke  and\\n      Koh, Pang Wei\",\\n    editor = \"Al-Onaizan, Yaser  and\\n      Bansal, Mohit  and\\n      Chen, Yun-Nung\",\\n    booktitle = \"Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing\",\\n    month = nov,\\n    year = \"2024\",\\n    address = \"Miami, Florida, USA\",\\n    publisher = \"Association for Computational Linguistics\",\\n    url = \"https://aclanthology.org/2024.emnlp-main.844/\",\\n    doi = \"10.18653/v1/2024.emnlp-main.844\",\\n    pages = \"15134--15158\",\\n    abstract = \"Evaluating the degree of reproduction of copyright-protected content by language models (LMs) is of significant interest to the AI and legal communities. Although both literal and non-literal similarities are considered by courts when assessing the degree of reproduction, prior research has focused only on literal similarities. To bridge this gap, we introduce CopyBench, a benchmark designed to measure both literal and non-literal copying in LM generations. Using copyrighted fiction books as text sources, we provide automatic evaluation protocols to assess literal and non-literal copying, balanced against the model utility in terms of the ability to recall facts from the copyrighted works and generate fluent completions. We find that, although literal copying is relatively rare, two types of non-literal copying{---}event copying and character copying{---}occur even in models as small as 7B parameters. Larger models demonstrate significantly more copying, with literal copying rates increasing from 0.2{\\\\%} to 10.5{\\\\%} and non-literal copying from 2.3{\\\\%} to 5.9{\\\\%} when comparing Llama3-8B and 70B models, respectively. We further evaluate the effectiveness of current strategies for mitigating copying and show that (1) training-time alignment can reduce literal copying but may increase non-literal copying, and (2) current inference-time mitigation methods primarily reduce literal but not non-literal copying.\"\\n}'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://aclanthology.org/2024.emnlp-main.844/\"\n",
    "\n",
    "def get_acl_bibtex(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        bibtex = soup.find(\"pre\", id=\"citeBibtexContent\").text\n",
    "        return bibtex\n",
    "    else:\n",
    "        print(f\"Failed to retrieve the page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "get_acl_bibtex(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@inproceedings{\\nwang2023on,\\ntitle={On Pre-training Language Model for Antibody},\\nauthor={Danqing Wang and Fei YE and Hao Zhou},\\nbooktitle={The Eleventh International Conference on Learning Representations },\\nyear={2023},\\nurl={https://openreview.net/forum?id=zaq4LV55xHl}\\n}'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_iclr_bibtex(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        open_review_url = soup.find(\"a\", title='OpenReview').get('href')\n",
    "\n",
    "        return get_openreview_bibtex(open_review_url)\n",
    "\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "def get_openreview_bibtex(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        props = soup.find(\"script\", id=\"__NEXT_DATA__\").text\n",
    "        props = json.loads(props)\n",
    "        bibtex = props['props']['pageProps']['forumNote']['content']['_bibtex']\n",
    "        return bibtex\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "get_iclr_bibtex(\"https://iclr.cc//virtual/2023/poster/10766\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@inproceedings{NEURIPS2022_e467582d,\\n author = {Xu, Minghao and Zhang, Zuobai and Lu, Jiarui and Zhu, Zhaocheng and Zhang, Yangtian and Chang, Ma and Liu, Runcheng and Tang, Jian},\\n booktitle = {Advances in Neural Information Processing Systems},\\n editor = {S. Koyejo and S. Mohamed and A. Agarwal and D. Belgrave and K. Cho and A. Oh},\\n pages = {35156--35173},\\n publisher = {Curran Associates, Inc.},\\n title = {PEER: A Comprehensive and Multi-Task Benchmark for Protein Sequence Understanding},\\n url = {https://proceedings.neurips.cc/paper_files/paper/2022/file/e467582d42d9c13fa9603df16f31de6d-Paper-Datasets_and_Benchmarks.pdf},\\n volume = {35},\\n year = {2022}\\n}\\n'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://neurips.cc//virtual/2022/poster/55752\"\n",
    "\n",
    "\n",
    "def get_neurips_bibtex(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        paper_page = soup.find(\"a\", title=\"Paper\").get(\"href\")\n",
    "        response = requests.get(paper_page)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            bibtex = soup.find(\"a\", string=\"Bibtex\").get(\"href\")\n",
    "            response = requests.get('https://proceedings.neurips.cc' + bibtex)\n",
    "            return response.text\n",
    "        else:\n",
    "            print(f\"Failed to retrieve the paper page. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "\n",
    "get_neurips_bibtex(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n@InProceedings{pmlr-v235-zhang24ad,\\n  title = \\t {Revisiting Zeroth-Order Optimization for Memory-Efficient {LLM} Fine-Tuning: A Benchmark},\\n  author =       {Zhang, Yihua and Li, Pingzhi and Hong, Junyuan and Li, Jiaxiang and Zhang, Yimeng and Zheng, Wenqing and Chen, Pin-Yu and Lee, Jason D. and Yin, Wotao and Hong, Mingyi and Wang, Zhangyang and Liu, Sijia and Chen, Tianlong},\\n  booktitle = \\t {Proceedings of the 41st International Conference on Machine Learning},\\n  pages = \\t {59173--59190},\\n  year = \\t {2024},\\n  editor = \\t {Salakhutdinov, Ruslan and Kolter, Zico and Heller, Katherine and Weller, Adrian and Oliver, Nuria and Scarlett, Jonathan and Berkenkamp, Felix},\\n  volume = \\t {235},\\n  series = \\t {Proceedings of Machine Learning Research},\\n  month = \\t {21--27 Jul},\\n  publisher =    {PMLR},\\n  pdf = \\t {https://raw.githubusercontent.com/mlresearch/v235/main/assets/zhang24ad/zhang24ad.pdf},\\n  url = \\t {https://proceedings.mlr.press/v235/zhang24ad.html},\\n  abstract = \\t {In the evolving landscape of natural language processing (NLP), fine-tuning pre-trained Large Language Models (LLMs) with first-order (FO) optimizers like SGD and Adam has become standard. Yet, as LLMs grow in size, the substantial memory overhead from back-propagation (BP) for FO gradient computation presents a significant challenge. Addressing this issue is crucial, especially for applications like on-device training where memory efficiency is paramount. This paper proposes a shift towards BP-free, zeroth-order (ZO) optimization as a solution for reducing memory costs during LLM fine-tuning, building on the initial concept introduced by (Malladi et al., 2023). Unlike traditional ZO-SGD methods, ou让work expands the exploration to a wider array of ZO optimization techniques, through a comprehensive, first-of-its-kind benchmarking study across five LLM families, three task complexities, and five fine-tuning schemes. Our study unveils previously overlooked optimization principles, highlighting the importance of task alignment, the role of the forward gradient method, and the balance between algorithm complexity and fine-tuning performance. We further introduce novel enhancements to ZO optimization, including block-wise descent, hybrid training, and gradient sparsity. Our study offers a promising direction for achieving further memory-efficient LLM fine-tuning. Codes to reproduce all our experiments will be made public.}\\n}\\n'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_icml_bibtex(url):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "        bib_page = soup.find(\"code\", id=\"bibtex\").text\n",
    "        return bib_page\n",
    "    else:\n",
    "        print(f\"Failed to retrieve page. Status code: {response.status_code}\")\n",
    "        return None\n",
    "    \n",
    "get_icml_bibtex('https://proceedings.mlr.press/v235/zhang24ad.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def get_conference_bibtex(url, venue):\n",
    "    time.sleep(1)  # To avoid overwhelming the server with requests\n",
    "    try:  \n",
    "        if venue == 'ICLR':\n",
    "            return get_iclr_bibtex(url)\n",
    "        elif venue == 'NeurIPS':\n",
    "            return get_neurips_bibtex(url)\n",
    "        elif venue == 'ICML':\n",
    "            return get_icml_bibtex(url)\n",
    "        else:\n",
    "            return get_acl_bibtex(url)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving bibtex: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "conferences_df = pd.read_csv('final_list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving bibtex: 'NoneType' object has no attribute 'get'\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n",
      "Error retrieving bibtex: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))\n"
     ]
    }
   ],
   "source": [
    "conferences_df['bibtex'] = conferences_df.apply(lambda x: get_conference_bibtex(x['link'],x['venue']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error retrieving bibtex: 'NoneType' object has no attribute 'get'\n"
     ]
    }
   ],
   "source": [
    "temp = conferences_df[conferences_df['bibtex'].isna()].apply(lambda x: get_conference_bibtex(x['link'],x['venue']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df['bibtex'] = conferences_df['bibtex'].fillna(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df = conferences_df[['title','summary','link','year','venue','inclusion','modality','contribution','bibtex']]\n",
    "conferences_df.to_csv('final_list_bibtex.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.bib', 'w') as file:\n",
    "    for i,row in conferences_df.iterrows():\n",
    "       print(row['bibtex'], file=file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Bibtex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "\n",
    "bibtex_writer = bibtexparser.bwriter.BibTexWriter()\n",
    "conferences_df['bibtex_clean'] = conferences_df['bibtex'].apply(lambda x: bibtexparser.loads(x))\n",
    "for i,row in conferences_df.iterrows():\n",
    "    row['bibtex_clean'].entries[0]['join_key'] = str(i)\n",
    "\n",
    "conferences_df['bibtex_clean'] = conferences_df['bibtex_clean'].apply(lambda x: bibtex_writer.write(x))\n",
    "conferences_df['bibtex_title'] = conferences_df['bibtex'].apply(lambda x: bibtexparser.loads(x).entries[0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/output.bib', 'w') as file:\n",
    "    for i,row in conferences_df.iterrows():\n",
    "       print(row['bibtex_clean'], file=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bibkeys.bib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbibkeys.bib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m bib_file:\n\u001b[0;32m      2\u001b[0m     bib_database \u001b[38;5;241m=\u001b[39m bibtexparser\u001b[38;5;241m.\u001b[39mload(bib_file)\n",
      "File \u001b[1;32mc:\\Users\\Andre\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bibkeys.bib'"
     ]
    }
   ],
   "source": [
    "with open('../data/bibkeys.bib', 'r') as bib_file:\n",
    "    bib_database = bibtexparser.load(bib_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibs = []\n",
    "for entry in bib_database.entries:\n",
    "    bibs.append({'join_key':int(entry['join_key']),'bibkey':entry['ID']})\n",
    "bibs_df = pd.DataFrame(bibs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibs_df.set_index('join_key', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df = conferences_df.merge(bibs_df,left_index=True,right_index=True,how='left')\n",
    "conferences_df.drop(['bibtex_clean','bibtex_title'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df.to_csv('final_list_bibtex.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing Bibtex author and editor information for *ACL venues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conferences_df = pd.read_csv('../data/final_list_bibtex.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "\n",
    "bibtex_writer = bibtexparser.bwriter.BibTexWriter()\n",
    "conferences_df['bibtex_clean'] = conferences_df['bibtex'].apply(lambda x: bibtexparser.loads(x))\n",
    "for i,row in conferences_df.iterrows():\n",
    "    row['bibtex_clean'].entries[0]['join_key'] = str(i)\n",
    "    row['bibtex_clean'].entries[0]['ID'] = row['bibkey']\n",
    "    row['bibtex_clean'].entries[0]['author'] = row['bibtex_clean'].entries[0]['author'].replace(' and ', ' and ')\n",
    "    row['bibtex_clean'].entries[0]['abstract'] = ''\n",
    "    row['bibtex_clean'].entries[0]['month'] = ''\n",
    "\n",
    "conferences_df['bibtex_clean'] = conferences_df['bibtex_clean'].apply(lambda x: bibtex_writer.write(x))\n",
    "conferences_df['bibtex_title'] = conferences_df['bibtex'].apply(lambda x: bibtexparser.loads(x).entries[0]['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/benchmark_review.bib', 'w') as file:\n",
    "    for i,row in conferences_df.iterrows():\n",
    "       print(row['bibtex_clean'], file=file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
